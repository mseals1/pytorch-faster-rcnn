+ echo Logging output to experiments/logs/test_vgg16_voc_2007_trainval_.txt.2018-05-24_18-44-39
Logging output to experiments/logs/test_vgg16_voc_2007_trainval_.txt.2018-05-24_18-44-39
+ set +x
+ [[ ! -z '' ]]
+ CUDA_VISIBLE_DEVICES=0
+ time python ./tools/test_net.py --imdb voc_2007_test --model output/vgg16/voc_2007_trainval/default/vgg16_faster_rcnn_iter_70000.pth --cfg experiments/cfgs/vgg16.yml --net vgg16 --set ANCHOR_SCALES '[8,16,32]' ANCHOR_RATIOS '[0.5,1,2]'
/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/colors.py:680: MatplotlibDeprecationWarning: The is_string_like function was deprecated in version 2.1.
  not cbook.is_string_like(colors[0]):
Called with args:
Namespace(cfg_file='experiments/cfgs/vgg16.yml', comp_mode=False, imdb_name='voc_2007_test', max_per_image=100, model='output/vgg16/voc_2007_trainval/default/vgg16_faster_rcnn_iter_70000.pth', net='vgg16', set_cfgs=['ANCHOR_SCALES', '[8,16,32]', 'ANCHOR_RATIOS', '[0.5,1,2]'], tag='')
Using config:
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32],
 'DATA_DIR': '/home/ubuntu/pytorch-faster-rcnn/data',
 'EXP_DIR': 'vgg16',
 'MATLAB': 'matlab',
 'MOBILENET': {'DEPTH_MULTIPLIER': 1.0,
               'FIXED_LAYERS': 5,
               'REGU_DEPTH': False,
               'WEIGHT_DECAY': 4e-05},
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'RESNET': {'FIXED_BLOCKS': 1, 'MAX_POOL': False},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/pytorch-faster-rcnn',
 'RPN_CHANNELS': 512,
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'MODE': 'nms',
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'gt',
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'RPN_TOP_N': 5000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': False,
           'BATCH_SIZE': 256,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'BIAS_DECAY': False,
           'DISPLAY': 20,
           'DOUBLE_BIAS': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'GAMMA': 0.1,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'LEARNING_RATE': 0.001,
           'MAX_SIZE': 1000,
           'MOMENTUM': 0.9,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_ITERS': 5000,
           'SNAPSHOT_KEPT': 3,
           'SNAPSHOT_PREFIX': 'vgg16_faster_rcnn',
           'STEPSIZE': [30000],
           'SUMMARY_INTERVAL': 180,
           'TRUNCATED': False,
           'USE_ALL_GT': True,
           'USE_FLIPPED': True,
           'USE_GT': False,
           'WEIGHT_DECAY': 0.0001},
 'USE_GPU_NMS': True}
Loading model check point from output/vgg16/voc_2007_trainval/default/vgg16_faster_rcnn_iter_70000.pth
Loaded.
/home/ubuntu/pytorch-faster-rcnn/tools/../lib/nets/network.py:245: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  rpn_cls_prob_reshape = F.softmax(rpn_cls_score_reshape)
/home/ubuntu/pytorch-faster-rcnn/tools/../lib/nets/network.py:280: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  cls_prob = F.softmax(cls_score)
im_detect: 1/64 1.051s 0.003s
im_detect: 2/64 0.683s 0.003s
im_detect: 3/64 0.551s 0.003s
im_detect: 4/64 0.491s 0.003s
im_detect: 5/64 0.453s 0.003s
im_detect: 6/64 0.429s 0.003s
im_detect: 7/64 0.408s 0.003s
im_detect: 8/64 0.395s 0.003s
im_detect: 9/64 0.383s 0.003s
im_detect: 10/64 0.372s 0.003s
im_detect: 11/64 0.365s 0.003s
im_detect: 12/64 0.357s 0.003s
im_detect: 13/64 0.352s 0.003s
im_detect: 14/64 0.347s 0.003s
im_detect: 15/64 0.343s 0.003s
im_detect: 16/64 0.340s 0.003s
im_detect: 17/64 0.339s 0.003s
im_detect: 18/64 0.336s 0.003s
im_detect: 19/64 0.333s 0.003s
im_detect: 20/64 0.331s 0.003s
im_detect: 21/64 0.327s 0.003s
im_detect: 22/64 0.325s 0.003s
im_detect: 23/64 0.324s 0.003s
im_detect: 24/64 0.322s 0.003s
im_detect: 25/64 0.321s 0.003s
im_detect: 26/64 0.320s 0.003s
im_detect: 27/64 0.319s 0.003s
im_detect: 28/64 0.318s 0.003s
im_detect: 29/64 0.316s 0.003s
im_detect: 30/64 0.315s 0.003s
im_detect: 31/64 0.314s 0.003s
im_detect: 32/64 0.313s 0.003s
im_detect: 33/64 0.312s 0.003s
im_detect: 34/64 0.312s 0.003s
im_detect: 35/64 0.311s 0.003s
im_detect: 36/64 0.311s 0.003s
im_detect: 37/64 0.310s 0.003s
im_detect: 38/64 0.309s 0.003s
im_detect: 39/64 0.308s 0.003s
im_detect: 40/64 0.307s 0.003s
im_detect: 41/64 0.307s 0.003s
im_detect: 42/64 0.306s 0.003s
im_detect: 43/64 0.306s 0.003s
im_detect: 44/64 0.305s 0.003s
im_detect: 45/64 0.305s 0.003s
im_detect: 46/64 0.305s 0.003s
im_detect: 47/64 0.304s 0.003s
im_detect: 48/64 0.304s 0.003s
im_detect: 49/64 0.304s 0.003s
im_detect: 50/64 0.303s 0.003s
im_detect: 51/64 0.303s 0.003s
im_detect: 52/64 0.302s 0.003s
im_detect: 53/64 0.302s 0.003s
im_detect: 54/64 0.302s 0.003s
im_detect: 55/64 0.301s 0.003s
im_detect: 56/64 0.301s 0.003s
im_detect: 57/64 0.301s 0.003s
im_detect: 58/64 0.301s 0.003s
im_detect: 59/64 0.300s 0.003s
im_detect: 60/64 0.300s 0.003s
im_detect: 61/64 0.300s 0.003s
im_detect: 62/64 0.300s 0.003s
im_detect: 63/64 0.300s 0.003s
im_detect: 64/64 0.299s 0.003s
Evaluating detections
Writing aeroplane VOC results file
Writing bicycle VOC results file
Writing bird VOC results file
Writing boat VOC results file
Writing bottle VOC results file
Writing bus VOC results file
Writing car VOC results file
Writing cat VOC results file
Writing chair VOC results file
Writing cow VOC results file
Writing diningtable VOC results file
Writing dog VOC results file
Writing horse VOC results file
Writing motorbike VOC results file
Writing person VOC results file
Writing pottedplant VOC results file
Writing sheep VOC results file
Writing sofa VOC results file
Writing train VOC results file
Writing tvmonitor VOC results file
VOC07 metric? Yes
Reading annotation for 1/64
Saving cached annotations to /home/ubuntu/pytorch-faster-rcnn/data/VOCdevkit2007/VOC2007/ImageSets/Main/test.txt_annots.pkl
/home/ubuntu/pytorch-faster-rcnn/tools/../lib/datasets/voc_eval.py:223: RuntimeWarning: invalid value encountered in true_divide
  rec = tp / float(npos)

recall =  [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]
precision =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 

/home/ubuntu/pytorch-faster-rcnn/tools/../lib/datasets/voc_eval.py:49: RuntimeWarning: invalid value encountered in greater_equal
  if np.sum(rec >= t) == 0:
AP for aeroplane = 0.0000

 bicycle
im_name = 007529_gblur_r5
max IoU = 0.767483195601

 bicycle
im_name = 006775_gblur_r5
max IoU = 0.156512229779

 bicycle
im_name = 002325_gblur_r5
max IoU = 0.356729200993

 bicycle
im_name = 007010_gblur_r5
max IoU = 0.479036423162

recall =  [ 0.          0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667]
precision =  [ 0.          0.5         0.33333333  0.25        0.2         0.16666667  0.14285714  0.125       0.11111111  0.1         0.09090909  0.08333333  0.07692308  0.07142857  0.06666667  0.0625      0.05882353  0.05555556  0.05263158  0.05        0.04761905  0.04545455  0.04347826  0.04166667  0.04        0.03846154  0.03703704  0.03571429  0.03448276  0.03333333  0.03225806  0.03125     0.03030303  0.02941176  0.02857143  0.02777778  0.02702703  0.02631579  0.02564103  0.025       0.02439024  0.02380952  0.02325581  0.02272727  0.02222222  0.02173913  0.0212766   0.02083333  0.02040816  0.02        0.01960784  0.01923077  0.01886792  0.01851852  0.01818182  0.01785714  0.01754386  0.01724138  0.01694915  0.01666667  0.01639344  0.01612903  0.01587302  0.015625    0.01538462  0.01515152  0.01492537  0.01470588  0.01449275  0.01428571  0.01408451  0.01388889  0.01369863  0.01351351  0.01333333  0.01315789  0.01298701  0.01282051  0.01265823  0.0125      0.01234568  0.01219512  0.01204819  0.01190476  0.01176471  0.01162791  0.01149425  0.01136364  0.01123596  0.01111111  0.01098901  0.01086957  0.01075269  0.0106383   0.01052632  0.01041667  0.01030928  0.01020408  0.01010101  0.01        0.00990099  0.00980392  0.00970874  0.00961538  0.00952381  0.00943396  0.00934579  0.00925926  0.00917431  0.00909091  0.00900901  0.00892857  0.00884956  0.00877193  0.00869565  0.00862069  0.00854701  0.00847458  0.00840336  0.00833333  0.00826446  0.00819672  0.00813008  0.00806452  0.008       0.00793651  0.00787402  0.0078125   0.00775194  0.00769231  0.00763359  0.00757576  0.0075188   0.00746269  0.00740741  0.00735294  0.00729927  0.00724638  0.00719424  0.00714286  0.0070922   0.00704225  0.00699301  0.00694444  0.00689655  0.00684932  0.00680272  0.00675676  0.00671141  0.00666667  0.00662252  0.00657895  0.00653595  0.00649351  0.00645161  0.00641026  0.00636943  0.00632911  0.00628931  0.00625     0.00621118  0.00617284  0.00613497  0.00609756  0.00606061  0.0060241   0.00598802  0.00595238  0.00591716  0.00588235  0.00584795  0.00581395  0.00578035  0.00574713  0.00571429  0.00568182  0.00564972  0.00561798  0.00558659  0.00555556  0.00552486  0.00549451  0.00546448  0.00543478  0.00540541  0.00537634  0.00534759  0.00531915  0.00529101  0.00526316  0.0052356   0.00520833] 

AP for bicycle = 0.0909

 bird
im_name = 001967_gblur_r5
max IoU = 0.325983152904

 bird
im_name = 002400_gblur_r5
max IoU = 0.63200081702

 bird
im_name = 003741_gblur_r5
max IoU = 0.353083406775

 bird
im_name = 007476_gblur_r5
max IoU = 0.406741569892

 bird
im_name = 002431_gblur_r5
max IoU = 0.164415229741

 bird
im_name = 008118_gblur_r5
max IoU = 0.371934448921

recall =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714]
precision =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.05882353  0.05555556  0.05263158  0.05        0.04761905  0.04545455  0.04347826  0.04166667  0.04        0.03846154  0.03703704  0.03571429  0.03448276  0.03333333  0.03225806  0.03125     0.03030303  0.02941176  0.02857143  0.02777778  0.02702703  0.02631579  0.02564103  0.025       0.02439024  0.02380952  0.02325581  0.02272727  0.02222222  0.02173913  0.0212766   0.02083333  0.02040816  0.02        0.01960784  0.01923077  0.01886792  0.01851852  0.01818182  0.01785714  0.01754386  0.01724138  0.01694915  0.01666667  0.01639344  0.01612903  0.01587302  0.015625    0.01538462  0.01515152  0.01492537  0.01470588  0.01449275  0.01428571  0.01408451  0.01388889  0.01369863  0.01351351  0.01333333  0.01315789  0.01298701  0.01282051  0.01265823  0.0125      0.01234568  0.01219512  0.01204819  0.01190476  0.01176471  0.01162791  0.01149425  0.01136364  0.01123596  0.01111111  0.01098901  0.01086957  0.01075269  0.0106383   0.01052632  0.01041667  0.01030928  0.01020408  0.01010101  0.01        0.00990099  0.00980392  0.00970874  0.00961538  0.00952381  0.00943396  0.00934579  0.00925926  0.00917431  0.00909091  0.00900901  0.00892857  0.00884956  0.00877193  0.00869565  0.00862069  0.00854701  0.00847458  0.00840336  0.00833333  0.00826446  0.00819672  0.00813008  0.00806452  0.008       0.00793651  0.00787402  0.0078125   0.00775194  0.00769231  0.00763359  0.00757576  0.0075188   0.00746269  0.00740741  0.00735294  0.00729927  0.00724638  0.00719424  0.00714286  0.0070922   0.00704225  0.00699301  0.00694444  0.00689655  0.00684932  0.00680272  0.00675676  0.00671141  0.00666667  0.00662252  0.00657895  0.00653595  0.00649351  0.00645161  0.00641026  0.00636943  0.00632911  0.00628931  0.00625     0.00621118  0.00617284  0.00613497  0.00609756  0.00606061  0.0060241   0.00598802  0.00595238  0.00591716  0.00588235  0.00584795  0.00581395  0.00578035  0.00574713  0.00571429  0.00568182  0.00564972  0.00561798  0.00558659  0.00555556  0.00552486  0.00549451  0.00546448  0.00543478  0.00540541  0.00537634  0.00534759  0.00531915  0.00529101  0.00526316  0.0052356   0.00520833  0.00518135  0.00515464  0.00512821  0.00510204  0.00507614  0.00505051  0.00502513  0.005       0.00497512  0.0049505   0.00492611  0.00490196  0.00487805  0.00485437  0.00483092  0.00480769  0.00478469  0.0047619   0.00473934  0.00471698  0.00469484  0.0046729   0.00465116  0.00462963  0.00460829  0.00458716  0.00456621  0.00454545  0.00452489  0.0045045   0.0044843   0.00446429  0.00444444  0.00442478  0.00440529  0.00438596  0.00436681  0.00434783  0.004329    0.00431034  0.00429185  0.0042735   0.00425532  0.00423729  0.00421941  0.00420168  0.0041841   0.00416667  0.00414938  0.00413223  0.00411523  0.00409836  0.00408163  0.00406504  0.00404858  0.00403226  0.00401606  0.004       0.00398406  0.00396825  0.00395257  0.00393701  0.00392157  0.00390625  0.00389105  0.00387597  0.003861    0.00384615  0.00383142  0.00381679  0.00380228  0.00378788  0.00377358  0.0037594   0.00374532  0.00373134  0.00371747  0.0037037   0.00369004  0.00367647  0.003663    0.00364964  0.00363636  0.00362319  0.00361011  0.00359712  0.00358423  0.00357143  0.00355872  0.0035461   0.00353357  0.00352113  0.00350877  0.0034965   0.00348432  0.00347222  0.00346021  0.00344828  0.00343643  0.00342466  0.00341297  0.00340136  0.00338983  0.00337838  0.003367    0.0033557   0.00334448  0.00333333  0.00332226  0.00331126  0.00330033  0.00328947  0.00327869  0.00326797  0.00325733  0.00324675  0.00323625  0.00322581  0.00321543  0.00320513  0.00319489  0.00318471  0.0031746   0.00316456  0.00315457  0.00314465  0.0031348   0.003125    0.00311526  0.00310559  0.00309598  0.00308642  0.00307692  0.00306748  0.0030581   0.00304878  0.00303951  0.0030303   0.00302115  0.00301205  0.003003    0.00299401  0.00298507  0.00297619  0.00296736  0.00295858  0.00294985  0.00294118  0.00293255  0.00292398  0.00291545  0.00290698  0.00289855  0.00289017  0.00288184  0.00287356  0.00286533  0.00285714  0.002849    0.00284091  0.00283286  0.00282486  0.0028169   0.00280899  0.00280112  0.0027933   0.00278552  0.00277778  0.00277008  0.00276243  0.00275482  0.00274725  0.00273973  0.00273224  0.0027248   0.00271739  0.00271003  0.0027027   0.00269542  0.00268817  0.00268097  0.0026738   0.00266667  0.00265957  0.00265252  0.0026455   0.00263852  0.00263158  0.00262467  0.0026178   0.00261097  0.00260417  0.0025974   0.00259067  0.00258398  0.00257732  0.00257069  0.0025641   0.00255754  0.00255102  0.00254453  0.00253807  0.00253165  0.00252525  0.00251889  0.00251256  0.00250627  0.0025      0.00249377  0.00248756  0.00248139  0.00247525  0.00246914  0.00246305  0.002457    0.00245098  0.00244499  0.00243902  0.00243309  0.00242718  0.00242131  0.00241546  0.00240964  0.00240385  0.00239808  0.00239234  0.00238663  0.00238095  0.0023753   0.00236967  0.00236407  0.00235849  0.00235294  0.00234742  0.00234192  0.00233645  0.002331    0.00232558  0.00232019  0.00231481  0.00230947  0.00230415  0.00229885  0.00229358  0.00228833  0.00228311  0.0022779   0.00227273  0.00226757  0.00226244  0.00225734  0.00225225  0.00224719  0.00224215  0.00223714  0.00223214  0.00222717  0.00222222  0.00221729  0.00221239  0.00220751  0.00220264  0.0021978   0.00219298  0.00218818  0.00218341  0.00217865  0.00217391  0.0021692   0.0021645   0.00215983  0.00215517  0.00215054  0.00214592  0.00214133  0.00213675  0.0021322   0.00212766  0.00212314  0.00211864  0.00211416  0.0021097   0.00210526  0.00210084  0.00209644  0.00209205  0.00208768  0.00208333  0.002079    0.00207469  0.00207039  0.00206612  0.00206186  0.00205761  0.00205339  0.00204918  0.00204499  0.00204082  0.00203666  0.00203252  0.0020284   0.00202429  0.0020202   0.00201613  0.00201207  0.00200803  0.00200401  0.002       0.00199601  0.00199203  0.00198807  0.00198413  0.0019802   0.00197628  0.00197239  0.0019685   0.00196464  0.00196078  0.00195695  0.00195312  0.00194932  0.00194553  0.00194175  0.00193798  0.00193424  0.0019305   0.00192678  0.00192308  0.00191939  0.00191571  0.00191205  0.0019084   0.00190476  0.00190114  0.00189753  0.00189394  0.00189036  0.00188679  0.00188324  0.0018797   0.00187617  0.00187266  0.00186916  0.00186567  0.0018622   0.00185874  0.00185529  0.00185185  0.00184843  0.00184502  0.00184162  0.00183824  0.00183486  0.0018315   0.00182815  0.00182482  0.00182149  0.00181818  0.00181488  0.00181159  0.00180832  0.00180505  0.0018018   0.00179856  0.00179533  0.00179211  0.00178891  0.00178571  0.00178253  0.00177936  0.0017762   0.00177305] 

AP for bird = 0.0107

 boat
im_name = 000538_gblur_r5
max IoU = 0.12360066645

 boat
im_name = 002390_gblur_r5
max IoU = 0.488197845711

 boat
im_name = 003012_gblur_r5
max IoU = 0.0156395093104

recall =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
precision =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 

AP for boat = 0.0000

 bottle
im_name = 004712_gblur_r5
max IoU = 0.0865941070791

 bottle
im_name = 000762_gblur_r5
max IoU = 0.37536721826

 bottle
im_name = 004072_gblur_r5
max IoU = 0.0429622571797

recall =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
precision =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 

AP for bottle = 0.0000

 bus
im_name = 002216_gblur_r5
max IoU = 0.597742605691

recall =  [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]
precision =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.01149425  0.01136364  0.01123596  0.01111111  0.01098901  0.01086957  0.01075269  0.0106383   0.01052632  0.02083333  0.02061856  0.02040816  0.02020202  0.02        0.01980198  0.01960784  0.01941748  0.01923077  0.01904762  0.01886792  0.01869159  0.01851852  0.01834862  0.01818182  0.01801802  0.01785714  0.01769912  0.01754386  0.0173913   0.01724138  0.01709402  0.01694915  0.01680672  0.01666667  0.01652893  0.01639344  0.01626016  0.01612903  0.016       0.01587302  0.01574803  0.015625    0.01550388  0.01538462  0.01526718  0.01515152  0.01503759  0.01492537  0.01481481  0.01470588  0.01459854  0.01449275  0.01438849  0.01428571  0.0141844   0.01408451  0.01398601  0.01388889  0.0137931   0.01369863  0.01360544  0.01351351  0.01342282  0.01333333  0.01324503  0.01315789  0.0130719   0.01298701  0.01290323  0.01282051  0.01273885  0.01265823  0.01257862  0.0125      0.01242236  0.01234568  0.01226994  0.01219512  0.01212121  0.01204819  0.01197605  0.01190476  0.01183432  0.01176471  0.01169591  0.01162791  0.01156069  0.01149425  0.01142857  0.01136364  0.01129944  0.01123596  0.01117318  0.01111111  0.01104972  0.01098901  0.01092896  0.01086957  0.01081081] 

AP for bus = 0.0208

 car
im_name = 005105_gblur_r5
max IoU = 0.659633374719

 car
im_name = 006481_gblur_r5
max IoU = 0.68356488324

 car
im_name = 000883_gblur_r5
max IoU = 0.612373087257

 car
im_name = 001283_gblur_r5
max IoU = 0.0890558272756

 car
im_name = 003701_gblur_r5
max IoU = 0.541838829882

recall =  [ 0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667]
precision =  [ 1.          0.5         0.33333333  0.25        0.2         0.16666667  0.14285714  0.125       0.11111111  0.1         0.09090909  0.08333333  0.07692308  0.07142857  0.06666667  0.125       0.11764706  0.11111111  0.10526316  0.1         0.0952381   0.09090909  0.08695652  0.08333333  0.08        0.07692308  0.07407407  0.07142857  0.06896552  0.06666667  0.06451613  0.0625      0.06060606  0.05882353  0.05714286  0.05555556  0.05405405  0.05263158  0.05128205  0.05        0.04878049  0.04761905  0.04651163  0.04545455  0.04444444  0.04347826  0.04255319  0.04166667  0.04081633  0.04        0.03921569  0.03846154  0.03773585  0.03703704  0.03636364  0.03571429  0.03508772  0.03448276  0.03389831  0.03333333  0.03278689  0.03225806  0.03174603  0.03125     0.03076923  0.03030303  0.02985075  0.02941176  0.02898551  0.02857143  0.02816901  0.02777778  0.02739726  0.02702703  0.02666667  0.02631579  0.02597403  0.02564103  0.02531646  0.025       0.02469136  0.02439024  0.02409639  0.02380952  0.02352941  0.02325581  0.02298851  0.02272727  0.02247191  0.02222222  0.02197802  0.02173913  0.02150538  0.0212766   0.02105263  0.02083333  0.02061856  0.02040816  0.02020202  0.02        0.01980198  0.01960784  0.01941748  0.01923077  0.01904762  0.01886792  0.01869159  0.01851852  0.01834862  0.01818182  0.01801802  0.01785714  0.01769912  0.01754386  0.0173913   0.01724138  0.01709402  0.01694915  0.01680672  0.01666667  0.01652893  0.01639344  0.01626016  0.01612903  0.016       0.01587302  0.01574803  0.015625    0.01550388  0.01538462  0.01526718  0.01515152  0.01503759  0.01492537  0.01481481  0.01470588  0.01459854  0.01449275  0.01438849  0.01428571  0.0141844   0.01408451  0.01398601  0.01388889  0.0137931   0.01369863  0.01360544  0.01351351  0.01342282  0.01333333  0.01324503  0.01315789  0.0130719   0.01298701  0.01290323  0.01282051  0.01273885  0.01265823  0.01257862  0.0125      0.01242236  0.01234568  0.01226994  0.01219512  0.01212121  0.01204819  0.01197605  0.01190476  0.01183432  0.01176471  0.01169591  0.01162791  0.01156069  0.01149425  0.01142857  0.01136364  0.01129944  0.01123596  0.01117318  0.01111111  0.01104972  0.01098901  0.01092896  0.01086957  0.01081081  0.01075269  0.01069519  0.0106383   0.01058201  0.01052632  0.0104712   0.01041667  0.01036269  0.01030928  0.01025641  0.01020408  0.01015228  0.01010101  0.01005025  0.01        0.00995025  0.00990099  0.00985222  0.00980392  0.0097561   0.00970874  0.00966184  0.00961538  0.00956938  0.01428571  0.01421801  0.01415094  0.01408451  0.01401869  0.01395349  0.01388889  0.01382488  0.01376147  0.01369863  0.01363636  0.01357466  0.01351351  0.01345291  0.01339286  0.01333333  0.01327434  0.01321586  0.01315789  0.01310044  0.01304348  0.01298701  0.01293103  0.01287554  0.01282051  0.01276596  0.01271186  0.01265823  0.01260504  0.0125523   0.0125      0.01244813  0.01239669  0.01234568  0.01229508  0.0122449   0.01219512  0.01214575  0.01209677  0.01204819  0.012       0.01195219  0.01190476  0.01185771  0.01181102  0.01176471  0.01171875  0.01167315  0.01162791  0.01158301  0.01153846  0.01149425  0.01145038  0.01140684  0.01136364  0.01132075  0.0112782   0.01123596  0.01119403  0.01115242  0.01111111  0.01107011  0.01102941  0.01098901  0.01094891  0.01090909  0.01086957  0.01083032  0.01079137  0.01075269  0.01071429  0.01067616  0.0141844   0.01413428  0.01408451  0.01403509  0.01398601  0.01393728  0.01388889  0.01384083  0.0137931   0.0137457   0.01369863  0.01365188  0.01360544  0.01355932  0.01351351  0.01346801  0.01342282  0.01337793  0.01333333  0.01328904  0.01324503  0.01320132  0.01315789  0.01311475  0.0130719   0.01302932  0.01298701  0.01294498  0.01290323  0.01286174  0.01282051  0.01277955  0.01273885  0.01269841  0.01265823  0.0126183   0.01257862  0.01253918  0.0125      0.01246106  0.01242236  0.0123839   0.01234568  0.01230769  0.01226994  0.01223242  0.01219512  0.01215805  0.01212121  0.01208459  0.01204819] 

AP for car = 0.2084

 cat
im_name = 006688_gblur_r5
max IoU = 0.77174891182

 cat
im_name = 007360_gblur_r5
max IoU = 0.420839798336

 cat
im_name = 006801_gblur_r5
max IoU = 0.568804646734

 cat
im_name = 008110_gblur_r5
max IoU = 0.305037526199

 cat
im_name = 000658_gblur_r5
max IoU = 0.14775432918

recall =  [ 0.    0.    0.    0.    0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 ]
precision =  [ 0.          0.          0.          0.          0.2         0.16666667  0.14285714  0.125       0.11111111  0.1         0.09090909  0.08333333  0.07692308  0.07142857  0.06666667  0.0625      0.05882353  0.05555556  0.05263158  0.05        0.04761905  0.04545455  0.04347826  0.04166667  0.04        0.03846154  0.03703704  0.07142857  0.06896552  0.06666667  0.06451613  0.0625      0.06060606  0.05882353  0.05714286  0.05555556  0.05405405  0.05263158  0.05128205  0.05        0.04878049  0.04761905  0.04651163  0.04545455  0.04444444  0.04347826  0.04255319  0.04166667  0.04081633  0.04        0.03921569  0.03846154  0.03773585  0.03703704  0.03636364  0.03571429  0.03508772  0.03448276  0.03389831  0.03333333  0.03278689  0.03225806  0.03174603  0.03125     0.03076923  0.03030303  0.02985075  0.02941176  0.02898551  0.02857143  0.02816901  0.02777778  0.02739726  0.02702703  0.02666667  0.02631579  0.02597403  0.02564103  0.02531646  0.025       0.02469136  0.02439024  0.02409639  0.02380952  0.02352941  0.02325581  0.02298851  0.02272727  0.02247191  0.02222222  0.02197802  0.02173913  0.02150538  0.0212766   0.02105263  0.02083333  0.02061856  0.02040816  0.02020202  0.02        0.01980198  0.01960784  0.01941748  0.01923077  0.01904762  0.01886792  0.01869159  0.01851852  0.01834862  0.01818182  0.01801802  0.01785714  0.01769912  0.01754386  0.0173913   0.01724138  0.01709402  0.01694915  0.01680672  0.01666667  0.01652893  0.01639344  0.01626016  0.01612903  0.016       0.01587302  0.01574803  0.015625    0.01550388  0.01538462  0.01526718  0.01515152  0.01503759  0.01492537  0.01481481  0.01470588  0.01459854  0.01449275  0.01438849  0.01428571  0.0141844   0.01408451  0.01398601  0.01388889  0.0137931   0.01369863  0.01360544  0.01351351  0.01342282  0.01333333  0.01324503  0.01315789  0.0130719   0.01298701  0.01290323  0.01282051  0.01273885  0.01265823  0.01257862  0.0125      0.01242236  0.01234568  0.01226994  0.01219512  0.01212121  0.01204819  0.01197605  0.01190476  0.01183432  0.01176471  0.01169591  0.01162791  0.01156069  0.01149425  0.01142857  0.01136364  0.01129944  0.01123596  0.01117318  0.01111111  0.01104972  0.01098901  0.01092896  0.01086957  0.01081081  0.01075269  0.01069519  0.0106383   0.01058201  0.01052632  0.0104712   0.01041667  0.01036269  0.01030928  0.01025641  0.01020408  0.01015228  0.01010101  0.01005025  0.01        0.00995025  0.00990099  0.00985222  0.00980392  0.0097561   0.00970874  0.00966184  0.00961538  0.00956938  0.00952381  0.00947867  0.00943396  0.00938967  0.00934579  0.00930233  0.00925926  0.00921659  0.00917431  0.00913242  0.00909091  0.00904977  0.00900901  0.00896861  0.00892857  0.00888889  0.00884956  0.00881057  0.00877193  0.00873362  0.00869565  0.00865801  0.00862069  0.00858369  0.00854701  0.00851064  0.00847458  0.00843882  0.00840336  0.0083682   0.00833333  0.00829876  0.00826446  0.00823045  0.00819672  0.00816327  0.00813008  0.00809717  0.00806452  0.00803213  0.008       0.00796813  0.00793651  0.00790514  0.00787402  0.00784314  0.0078125   0.0077821   0.00775194  0.00772201  0.00769231  0.00766284  0.00763359  0.00760456  0.00757576  0.00754717  0.0075188   0.00749064  0.00746269  0.00743494  0.00740741  0.00738007  0.00735294  0.00732601  0.00729927  0.00727273  0.00724638  0.00722022  0.00719424  0.00716846  0.00714286  0.00711744  0.0070922   0.00706714  0.00704225  0.00701754  0.00699301  0.00696864  0.00694444  0.00692042  0.00689655  0.00687285  0.00684932  0.00682594  0.00680272  0.00677966  0.00675676  0.00673401  0.00671141  0.00668896  0.00666667  0.00664452  0.00662252  0.00660066  0.00657895  0.00655738  0.00653595  0.00651466  0.00649351  0.00647249  0.00645161  0.00643087  0.00641026  0.00638978  0.00636943  0.00634921  0.00632911  0.00630915  0.00628931  0.00626959  0.00625     0.00623053  0.00621118  0.00619195  0.00617284  0.00615385  0.00613497  0.00611621  0.00609756  0.00607903  0.00606061  0.0060423   0.0060241   0.00600601  0.00598802  0.00597015  0.00595238  0.00593472  0.00591716  0.00589971  0.00588235  0.0058651   0.00584795  0.0058309   0.00581395  0.0057971   0.00578035  0.00576369  0.00574713  0.00573066  0.00571429  0.00569801  0.00568182  0.00566572  0.00564972  0.0056338   0.00561798  0.00560224  0.00558659  0.00557103  0.00555556  0.00554017  0.00552486  0.00550964  0.00549451  0.00547945  0.00546448  0.00544959  0.00543478  0.00542005  0.00540541  0.00539084  0.00537634  0.00536193  0.00534759  0.00533333  0.00531915  0.00530504  0.00529101  0.00527704  0.00526316  0.00524934  0.0052356   0.00522193  0.00520833  0.00519481  0.00518135  0.00516796  0.00515464  0.00514139  0.00512821  0.00511509  0.00510204  0.00508906  0.00507614  0.00506329  0.00505051  0.00503778  0.00502513  0.00501253  0.005       0.00498753  0.00497512  0.00496278  0.0049505   0.00493827  0.00492611  0.004914    0.00490196  0.00488998  0.00487805  0.00486618  0.00485437  0.00484262  0.00483092  0.00481928  0.00480769  0.00479616  0.00478469  0.00477327  0.0047619   0.00475059  0.00473934  0.00472813  0.00471698  0.00470588  0.00469484  0.00468384  0.0046729   0.004662    0.00465116  0.00464037  0.00462963  0.00461894  0.00460829  0.0045977   0.00458716  0.00457666  0.00456621  0.00455581  0.00454545  0.00453515  0.00452489  0.00451467  0.0045045   0.00449438  0.0044843   0.00447427  0.00446429  0.00445434  0.00444444  0.00443459  0.00442478  0.00441501  0.00440529  0.0043956   0.00438596  0.00437637  0.00436681  0.0043573   0.00434783  0.00433839  0.004329    0.00431965  0.00431034  0.00430108  0.00429185  0.00428266  0.0042735   0.00426439  0.00425532  0.00424628  0.00423729  0.00422833  0.00421941  0.00421053  0.00420168  0.00419287  0.0041841   0.00417537  0.00416667  0.004158    0.00414938  0.00414079  0.00413223  0.00412371  0.00411523  0.00410678  0.00409836  0.00408998  0.00408163  0.00407332  0.00406504  0.0040568   0.00404858  0.0040404   0.00403226  0.00402414  0.00401606  0.00400802  0.004       0.00399202  0.00398406  0.00397614  0.00396825] 

AP for cat = 0.0740

 chair
im_name = 002724_gblur_r5
max IoU = 0.63938353459

 chair
im_name = 002365_gblur_r5
max IoU = 0.549030005496

 chair
im_name = 004712_gblur_r5
max IoU = 0.100318707572

 chair
im_name = 007207_gblur_r5
max IoU = 0.0521504874705

 chair
im_name = 000377_gblur_r5
max IoU = 0.47495993013

 chair
im_name = 007785_gblur_r5
max IoU = 0.476274806675

 chair
im_name = 008110_gblur_r5
max IoU = 0.583859112755

 chair
im_name = 005218_gblur_r5
max IoU = 0.364615223642

 chair
im_name = 005934_gblur_r5
max IoU = 0.762745146215

 chair
im_name = 008543_gblur_r5
max IoU = 0.276879124624

 chair
im_name = 006307_gblur_r5
max IoU = 0.408841042388

recall =  [ 0.      0.      0.      0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.0625  0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25  ]
precision =  [ 0.          0.          0.          0.25        0.2         0.16666667  0.14285714  0.125       0.11111111  0.1         0.09090909  0.08333333  0.07692308  0.07142857  0.06666667  0.0625      0.05882353  0.05555556  0.05263158  0.05        0.04761905  0.04545455  0.04347826  0.04166667  0.04        0.03846154  0.03703704  0.03571429  0.03448276  0.03333333  0.03225806  0.03125     0.03030303  0.02941176  0.02857143  0.02777778  0.02702703  0.02631579  0.02564103  0.025       0.02439024  0.02380952  0.02325581  0.02272727  0.02222222  0.02173913  0.0212766   0.02083333  0.02040816  0.02        0.01960784  0.01923077  0.01886792  0.01851852  0.01818182  0.01785714  0.01754386  0.01724138  0.01694915  0.01666667  0.01639344  0.03225806  0.03174603  0.03125     0.03076923  0.03030303  0.02985075  0.02941176  0.02898551  0.02857143  0.02816901  0.02777778  0.02739726  0.02702703  0.02666667  0.02631579  0.02597403  0.02564103  0.02531646  0.0375      0.03703704  0.03658537  0.03614458  0.03571429  0.03529412  0.03488372  0.03448276  0.03409091  0.03370787  0.03333333  0.03296703  0.0326087   0.03225806  0.03191489  0.03157895  0.03125     0.03092784  0.03061224  0.03030303  0.03        0.02970297  0.02941176  0.02912621  0.02884615  0.02857143  0.03773585  0.03738318  0.03703704  0.03669725  0.03636364  0.03603604  0.03571429  0.03539823  0.03508772  0.03478261  0.03448276  0.03418803  0.03389831  0.03361345  0.03333333  0.03305785  0.03278689  0.03252033  0.03225806  0.032       0.03174603  0.03149606  0.03125     0.03100775  0.03076923  0.03053435  0.03030303  0.03007519  0.02985075  0.02962963  0.02941176  0.02919708  0.02898551  0.02877698  0.02857143  0.02836879  0.02816901  0.02797203  0.02777778  0.02758621  0.02739726  0.02721088  0.02702703  0.02684564  0.02666667  0.02649007  0.02631579  0.02614379  0.02597403  0.02580645  0.02564103  0.02547771  0.02531646  0.02515723  0.025       0.02484472  0.02469136  0.02453988  0.02439024  0.02424242  0.02409639  0.0239521   0.02380952  0.02366864  0.02352941  0.02339181  0.02325581  0.02312139  0.02298851  0.02285714  0.02272727  0.02259887  0.02247191  0.02234637  0.02222222  0.02209945  0.02197802  0.02185792  0.02173913  0.02162162  0.02150538  0.02139037  0.0212766   0.02116402  0.02105263  0.02094241  0.02083333  0.02072539  0.02061856  0.02051282  0.02040816  0.02030457  0.02020202  0.0201005   0.02        0.0199005   0.01980198  0.01970443  0.01960784  0.0195122   0.01941748  0.01932367  0.01923077  0.01913876  0.01904762  0.01895735  0.01886792  0.01877934  0.01869159  0.01860465  0.01851852  0.01843318  0.01834862  0.01826484  0.01818182  0.01809955  0.01801802  0.01793722  0.01785714  0.01777778  0.01769912  0.01762115  0.01754386  0.01746725  0.0173913   0.01731602  0.01724138  0.01716738  0.01709402  0.01702128  0.01694915  0.01687764  0.01680672  0.0167364   0.01666667  0.01659751  0.01652893  0.01646091  0.01639344  0.01632653  0.01626016  0.01619433  0.01612903  0.01606426  0.016       0.01593625  0.01587302  0.01581028  0.01574803  0.01568627  0.015625    0.0155642   0.01550388  0.01544402  0.01538462  0.01532567  0.01526718  0.01520913  0.01515152  0.01509434  0.01503759  0.01498127  0.01492537  0.01486989  0.01481481  0.01476015  0.01470588  0.01465201  0.01459854  0.01454545  0.01449275  0.01444043  0.01438849  0.01433692  0.01428571  0.01423488  0.0141844   0.01413428  0.01408451  0.01403509  0.01398601  0.01393728  0.01388889  0.01384083  0.0137931   0.0137457   0.01369863  0.01365188  0.01360544  0.01355932  0.01351351  0.01346801  0.01342282  0.01337793  0.01333333  0.01328904] 

AP for chair = 0.0296

 cow
im_name = 000273_gblur_r5
max IoU = 0.0258040099431

 cow
im_name = 004375_gblur_r5
max IoU = 0.104948002074

recall =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
precision =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 

AP for cow = 0.0000

 diningtable
im_name = 002724_gblur_r5
max IoU = 0.350376867958

 diningtable
im_name = 007207_gblur_r5
max IoU = 0.483474592294

 diningtable
im_name = 000377_gblur_r5
max IoU = 0.363137197783

 diningtable
im_name = 000762_gblur_r5
max IoU = 0.863061471159

 diningtable
im_name = 004712_gblur_r5
max IoU = 0.15178160305

recall =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
precision =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 

AP for diningtable = 0.0000

 dog
im_name = 005117_gblur_r5
max IoU = 0.433063106181

 dog
im_name = 009176_gblur_r5
max IoU = 0.609105314739

 dog
im_name = 005684_gblur_r5
max IoU = 0.104081450521

 dog
im_name = 006182_gblur_r5
max IoU = 0.614541815181

recall =  [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4]
precision =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.07142857  0.06666667  0.0625      0.05882353  0.05555556  0.05263158  0.05        0.04761905  0.04545455  0.04347826  0.04166667  0.04        0.03846154  0.03703704  0.03571429  0.03448276  0.03333333  0.03225806  0.03125     0.03030303  0.02941176  0.02857143  0.02777778  0.02702703  0.02631579  0.02564103  0.025       0.02439024  0.02380952  0.02325581  0.02272727  0.02222222  0.02173913  0.0212766   0.02083333  0.02040816  0.02        0.01960784  0.01923077  0.01886792  0.01851852  0.01818182  0.01785714  0.01754386  0.01724138  0.01694915  0.01666667  0.01639344  0.01612903  0.01587302  0.015625    0.01538462  0.01515152  0.01492537  0.01470588  0.01449275  0.01428571  0.01408451  0.01388889  0.01369863  0.01351351  0.01333333  0.01315789  0.01298701  0.01282051  0.01265823  0.0125      0.01234568  0.01219512  0.01204819  0.01190476  0.01176471  0.01162791  0.01149425  0.01136364  0.01123596  0.01111111  0.01098901  0.01086957  0.01075269  0.0106383   0.01052632  0.01041667  0.01030928  0.01020408  0.01010101  0.01        0.00990099  0.00980392  0.00970874  0.00961538  0.00952381  0.00943396  0.00934579  0.00925926  0.00917431  0.00909091  0.00900901  0.00892857  0.00884956  0.00877193  0.00869565  0.00862069  0.00854701  0.00847458  0.00840336  0.00833333  0.00826446  0.00819672  0.00813008  0.00806452  0.008       0.00793651  0.00787402  0.0078125   0.00775194  0.00769231  0.00763359  0.00757576  0.0075188   0.00746269  0.00740741  0.00735294  0.00729927  0.00724638  0.00719424  0.00714286  0.0070922   0.00704225  0.00699301  0.00694444  0.00689655  0.00684932  0.00680272  0.00675676  0.00671141  0.00666667  0.00662252  0.00657895  0.00653595  0.00649351  0.00645161  0.00641026  0.00636943  0.00632911  0.00628931  0.00625     0.00621118  0.00617284  0.00613497  0.00609756  0.00606061  0.0060241   0.00598802  0.00595238  0.00591716  0.00588235  0.00584795  0.00581395  0.00578035  0.00574713  0.00571429  0.00568182  0.00564972  0.00561798  0.00558659  0.00555556  0.00552486  0.00549451  0.00546448  0.00543478  0.00540541  0.00537634  0.00534759  0.00531915  0.00529101  0.00526316  0.0052356   0.00520833  0.00518135  0.00515464  0.00512821  0.00510204  0.00507614  0.00505051  0.00502513  0.005       0.00497512  0.0049505   0.00492611  0.00490196  0.00487805  0.00485437  0.00483092  0.00480769  0.00478469  0.0047619   0.00473934  0.00471698  0.00469484  0.0046729   0.00465116  0.00462963  0.00460829  0.00458716  0.00456621  0.00454545  0.00452489  0.0045045   0.0044843   0.00446429  0.00444444  0.00442478  0.00440529  0.00438596  0.00436681  0.00434783  0.004329    0.00431034  0.00429185  0.0042735   0.00425532  0.00423729  0.00421941  0.00420168  0.0041841   0.00416667  0.00414938  0.00413223  0.00411523  0.00409836  0.00408163  0.00406504  0.00404858  0.00403226  0.00401606  0.004       0.00398406  0.00396825  0.00395257  0.00393701  0.00392157  0.00390625  0.00389105  0.00387597  0.003861    0.00384615  0.00383142  0.00381679  0.00380228  0.00378788  0.00377358  0.0037594   0.00374532  0.00373134  0.00371747  0.0037037   0.00369004  0.00367647  0.003663    0.00364964  0.00363636  0.00362319  0.00361011  0.00359712  0.00358423  0.00357143  0.00355872  0.0035461   0.00353357  0.00352113  0.00350877  0.0034965   0.00348432  0.00347222  0.00346021  0.00344828  0.00343643  0.00342466  0.00341297  0.00340136  0.00338983  0.00337838  0.003367    0.0033557   0.00334448  0.00333333  0.00332226  0.00331126  0.00330033  0.00328947  0.00327869  0.00326797  0.00325733  0.00649351  0.00647249  0.00645161  0.00643087  0.00641026  0.00638978  0.00636943  0.00634921  0.00632911  0.00630915  0.00628931  0.00626959  0.00625     0.00623053  0.00621118  0.00619195  0.00617284  0.00615385  0.00613497  0.00611621  0.00609756  0.00607903  0.00606061  0.0060423   0.0060241   0.00600601  0.00598802  0.00597015  0.00595238  0.00593472  0.00591716  0.00589971  0.00588235  0.0058651   0.00584795  0.0058309   0.00581395  0.0057971   0.00578035  0.00576369  0.00574713  0.00573066  0.00571429  0.00569801  0.00568182  0.00566572  0.00564972  0.0056338   0.00561798  0.00560224  0.00558659  0.00557103  0.00555556] 

AP for dog = 0.0207

 horse
im_name = 008812_gblur_r5
max IoU = 0.359590191356

 horse
im_name = 007055_gblur_r5
max IoU = 0.718540103542

 horse
im_name = 003764_gblur_r5
max IoU = 0.29928527613

 horse
im_name = 009661_gblur_r5
max IoU = 0.545764990297

recall =  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 ]
precision =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.01886792  0.01851852  0.01818182  0.01785714  0.01754386  0.01724138  0.01694915  0.01666667  0.01639344  0.01612903  0.01587302  0.015625    0.01538462  0.01515152  0.01492537  0.01470588  0.01449275  0.01428571  0.01408451  0.01388889  0.01369863  0.01351351  0.01333333  0.01315789  0.01298701  0.01282051  0.01265823  0.0125      0.01234568  0.01219512  0.01204819  0.01190476  0.01176471  0.01162791  0.01149425  0.01136364  0.01123596  0.01111111  0.01098901  0.01086957  0.01075269  0.0106383   0.01052632  0.01041667  0.01030928  0.01020408  0.01010101  0.01        0.00990099  0.00980392  0.00970874  0.00961538  0.00952381  0.00943396  0.00934579  0.01851852  0.01834862  0.01818182  0.01801802  0.01785714  0.01769912  0.01754386  0.0173913   0.01724138] 

AP for horse = 0.0102

 motorbike
im_name = 009139_gblur_r5
max IoU = 0.721320571178

 motorbike
im_name = 004243_gblur_r5
max IoU = 0.525931174837

 motorbike
im_name = 006531_gblur_r5
max IoU = 0.0115283432553

 motorbike
im_name = 009639_gblur_r5
max IoU = 0.696479213092

recall =  [ 0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.18181818  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727  0.27272727]
precision =  [ 1.          0.5         0.33333333  0.25        0.2         0.16666667  0.14285714  0.125       0.11111111  0.1         0.09090909  0.08333333  0.15384615  0.14285714  0.13333333  0.125       0.11764706  0.11111111  0.10526316  0.1         0.0952381   0.09090909  0.08695652  0.08333333  0.08        0.07692308  0.07407407  0.07142857  0.06896552  0.06666667  0.06451613  0.0625      0.06060606  0.05882353  0.05714286  0.05555556  0.05405405  0.05263158  0.05128205  0.05        0.04878049  0.04761905  0.04651163  0.04545455  0.04444444  0.04347826  0.04255319  0.04166667  0.04081633  0.04        0.03921569  0.03846154  0.03773585  0.03703704  0.03636364  0.03571429  0.03508772  0.03448276  0.03389831  0.03333333  0.03278689  0.03225806  0.03174603  0.03125     0.03076923  0.03030303  0.02985075  0.02941176  0.02898551  0.02857143  0.02816901  0.02777778  0.02739726  0.02702703  0.02666667  0.02631579  0.02597403  0.02564103  0.02531646  0.025       0.02469136  0.02439024  0.02409639  0.02380952  0.02352941  0.02325581  0.02298851  0.02272727  0.02247191  0.02222222  0.02197802  0.02173913  0.02150538  0.0212766   0.02105263  0.02083333  0.02061856  0.02040816  0.02020202  0.02        0.01980198  0.01960784  0.01941748  0.01923077  0.01904762  0.01886792  0.01869159  0.01851852  0.01834862  0.01818182  0.01801802  0.01785714  0.01769912  0.01754386  0.0173913   0.01724138  0.01709402  0.01694915  0.01680672  0.01666667  0.01652893  0.01639344  0.01626016  0.01612903  0.016       0.01587302  0.01574803  0.015625    0.01550388  0.01538462  0.01526718  0.01515152  0.01503759  0.01492537  0.01481481  0.01470588  0.01459854  0.01449275  0.01438849  0.01428571  0.0141844   0.01408451  0.01398601  0.01388889  0.0137931   0.01369863  0.01360544  0.01351351  0.01342282  0.01333333  0.01324503  0.01315789  0.0130719   0.01298701  0.01290323  0.01282051  0.01273885  0.01265823  0.01257862  0.0125      0.01242236  0.01234568  0.01226994  0.01219512  0.01212121  0.01204819  0.01796407  0.01785714  0.01775148  0.01764706  0.01754386  0.01744186  0.01734104  0.01724138  0.01714286  0.01704545  0.01694915  0.01685393  0.01675978  0.01666667  0.01657459  0.01648352  0.01639344  0.01630435  0.01621622  0.01612903  0.01604278] 

AP for motorbike = 0.1065

 person
im_name = 000502_gblur_r5
max IoU = 0.870737535014

 person
im_name = 005117_gblur_r5
max IoU = 0.591665148479

 person
im_name = 004709_gblur_r5
max IoU = 0.749520295579

 person
im_name = 007161_gblur_r5
max IoU = 0.780800740772

 person
im_name = 002365_gblur_r5
max IoU = 0.616825066181

 person
im_name = 004072_gblur_r5
max IoU = 0.705865296326

 person
im_name = 004712_gblur_r5
max IoU = 0.462531995217

 person
im_name = 007360_gblur_r5
max IoU = 0.425493598139

 person
im_name = 009139_gblur_r5
max IoU = 0.482999050737

 person
im_name = 006481_gblur_r5
max IoU = 0.189684541043

 person
im_name = 000377_gblur_r5
max IoU = 0.748323260303

 person
im_name = 004639_gblur_r5
max IoU = 0.622947507409

 person
im_name = 005105_gblur_r5
max IoU = 0.0677037592996

 person
im_name = 009661_gblur_r5
max IoU = 0.246155254215

 person
im_name = 006087_gblur_r5
max IoU = 0.894896643984

 person
im_name = 000538_gblur_r5
max IoU = 0.296917798294

 person
im_name = 008110_gblur_r5
max IoU = 0.46825142918

 person
im_name = 006775_gblur_r5
max IoU = 0.290230596031

 person
im_name = 005218_gblur_r5
max IoU = 0.415659295362

 person
im_name = 003012_gblur_r5
max IoU = 0.520175913275

 person
im_name = 007207_gblur_r5
max IoU = 0.575739231849

 person
im_name = 001482_gblur_r5
max IoU = 0.564340034884

 person
im_name = 004243_gblur_r5
max IoU = 0.155399023414

 person
im_name = 000762_gblur_r5
max IoU = 0.532742161387

 person
im_name = 008812_gblur_r5
max IoU = 0.32426603543

 person
im_name = 007785_gblur_r5
max IoU = 0.700681000669

 person
im_name = 000883_gblur_r5
max IoU = 0.092395029388

 person
im_name = 003701_gblur_r5
max IoU = 0.437782258065

 person
im_name = 000458_gblur_r5
max IoU = 0.429891418232

 person
im_name = 006531_gblur_r5
max IoU = 0.00817453175638

 person
im_name = 002325_gblur_r5
max IoU = 0.444992344763

 person
im_name = 007476_gblur_r5
max IoU = 0.491492152864

 person
im_name = 003764_gblur_r5
max IoU = 0.23411678296

 person
im_name = 006307_gblur_r5
max IoU = 0.0944903795143

recall =  [ 0.01333333  0.02666667  0.04        0.05333333  0.05333333  0.06666667  0.08        0.08        0.08        0.08        0.08        0.08        0.08        0.08        0.08        0.08        0.08        0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.09333333  0.10666667  0.10666667  0.10666667  0.10666667  0.10666667  0.10666667  0.10666667  0.10666667  0.10666667  0.10666667  0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.12        0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.14666667  0.14666667  0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.16        0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.17333333  0.18666667  0.18666667  0.18666667  0.18666667  0.18666667  0.18666667  0.18666667  0.18666667  0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2         0.2       ]
precision =  [ 1.          1.          1.          1.          0.8         0.83333333  0.85714286  0.75        0.66666667  0.6         0.54545455  0.5         0.46153846  0.42857143  0.4         0.375       0.35294118  0.38888889  0.36842105  0.35        0.33333333  0.31818182  0.30434783  0.29166667  0.28        0.26923077  0.25925926  0.25        0.24137931  0.23333333  0.22580645  0.21875     0.21212121  0.20588235  0.2         0.22222222  0.21621622  0.21052632  0.20512821  0.2         0.19512195  0.19047619  0.18604651  0.18181818  0.17777778  0.19565217  0.19148936  0.1875      0.18367347  0.18        0.17647059  0.17307692  0.16981132  0.16666667  0.16363636  0.16071429  0.15789474  0.15517241  0.15254237  0.15        0.14754098  0.14516129  0.14285714  0.140625    0.13846154  0.15151515  0.14925373  0.14705882  0.14492754  0.14285714  0.14084507  0.13888889  0.1369863   0.13513514  0.13333333  0.13157895  0.12987013  0.12820513  0.12658228  0.125       0.12345679  0.12195122  0.12048193  0.11904762  0.11764706  0.11627907  0.11494253  0.11363636  0.11235955  0.11111111  0.10989011  0.10869565  0.10752688  0.10638298  0.10526316  0.10416667  0.10309278  0.10204082  0.1010101   0.1         0.0990099   0.09803922  0.09708738  0.09615385  0.0952381   0.09433962  0.09345794  0.09259259  0.09174312  0.09090909  0.09009009  0.08928571  0.08849558  0.0877193   0.08695652  0.0862069   0.08547009  0.08474576  0.08403361  0.08333333  0.08264463  0.08196721  0.08130081  0.08064516  0.08        0.07936508  0.07874016  0.078125    0.07751938  0.07692308  0.07633588  0.07575758  0.07518797  0.07462687  0.07407407  0.07352941  0.0729927   0.07246377  0.07194245  0.07142857  0.07092199  0.07042254  0.06993007  0.06944444  0.06896552  0.06849315  0.06802721  0.06756757  0.06711409  0.06666667  0.06622517  0.06578947  0.06535948  0.06493506  0.06451613  0.06410256  0.06369427  0.06329114  0.06289308  0.0625      0.0621118   0.0617284   0.06134969  0.06097561  0.06060606  0.06024096  0.05988024  0.05952381  0.0591716   0.05882353  0.05847953  0.05813953  0.05780347  0.05747126  0.05714286  0.05681818  0.05649718  0.05617978  0.05586592  0.05555556  0.05524862  0.05494505  0.05464481  0.05434783  0.05405405  0.05376344  0.05347594  0.05851064  0.05820106  0.06315789  0.06282723  0.0625      0.06217617  0.06185567  0.06153846  0.06122449  0.06091371  0.06060606  0.06030151  0.06        0.05970149  0.05940594  0.0591133   0.05882353  0.05853659  0.05825243  0.05797101  0.05769231  0.05741627  0.05714286  0.05687204  0.05660377  0.05633803  0.05607477  0.05581395  0.05581395  0.05555556  0.05529954  0.05504587  0.05479452  0.05454545  0.05882353  0.05855856  0.05829596  0.05803571  0.05777778  0.05752212  0.05726872  0.05701754  0.05676856  0.05652174  0.05627706  0.05603448  0.05579399  0.05555556  0.05531915  0.05508475  0.05485232  0.05462185  0.05439331  0.05416667  0.05394191  0.05371901  0.05349794  0.05327869  0.05306122  0.05284553  0.05263158  0.05241935  0.05220884  0.052       0.05179283  0.0515873   0.0513834   0.0511811   0.05098039  0.05078125  0.05058366  0.0503876   0.05019305  0.05        0.04980843  0.04961832  0.04942966  0.04924242  0.0490566   0.04887218  0.04868914  0.04850746  0.04832714  0.04814815  0.04797048  0.04779412  0.04761905  0.04744526  0.04727273  0.04710145  0.04693141  0.04676259  0.04659498  0.04642857  0.04626335  0.04609929  0.0459364   0.04577465  0.04561404  0.04545455  0.04529617  0.04513889  0.0449827   0.04482759  0.04467354  0.04452055  0.0443686   0.04421769  0.0440678   0.04391892  0.04377104  0.04362416  0.04347826  0.04333333  0.04318937  0.04304636  0.04290429  0.04276316  0.04262295  0.04248366  0.04234528  0.04220779  0.0420712   0.04193548  0.04180064  0.04166667  0.04153355  0.04140127  0.04126984  0.04113924  0.04100946  0.0408805   0.04075235  0.040625    0.04049844  0.04037267  0.04024768  0.04012346  0.04        0.0398773   0.03975535  0.03963415  0.03951368  0.03939394  0.03927492  0.03915663  0.03903904  0.03892216  0.03880597  0.03869048  0.03857567  0.03846154  0.04129794  0.04117647  0.04105572  0.04093567  0.04081633  0.04069767  0.04057971  0.04046243  0.04322767  0.04310345  0.04297994  0.04285714  0.04273504  0.04261364  0.04249292  0.04237288  0.04225352  0.04213483  0.04201681  0.04189944  0.04178273  0.04166667  0.04155125  0.04143646  0.04132231  0.04120879  0.04109589  0.04098361  0.04087193  0.04076087  0.04065041  0.04054054  0.04043127  0.04032258  0.04021448  0.04010695  0.04        0.03989362  0.0397878   0.03968254  0.03957784  0.03947368  0.03937008  0.03926702  0.03916449  0.0390625   0.03896104  0.0388601   0.03875969  0.03865979  0.03856041  0.03846154  0.03836317  0.03826531  0.03816794  0.03807107  0.03797468  0.03787879  0.03778338  0.03768844  0.03759398  0.0375      0.03740648  0.03731343  0.03722084  0.03712871  0.03703704  0.03694581  0.03685504  0.03676471  0.03667482  0.03658537  0.03649635  0.03640777  0.03631961  0.03623188  0.03614458  0.03605769  0.03597122  0.03588517  0.03579952  0.03571429  0.03562945  0.03554502  0.03546099  0.03537736  0.03529412  0.03521127  0.03512881  0.03504673  0.03496503  0.03488372  0.03480278  0.03472222  0.03464203  0.03456221  0.03448276  0.03440367  0.03432494  0.03424658  0.03416856  0.03409091  0.03401361  0.03393665  0.03386005  0.03378378  0.03370787  0.03363229  0.03355705  0.03348214  0.03340757  0.03333333  0.03325942  0.03318584  0.03311258  0.03303965  0.03296703  0.03289474  0.03282276  0.03275109  0.03267974  0.0326087   0.03253796  0.03246753  0.03239741  0.03232759  0.03225806  0.03218884  0.03211991  0.03205128  0.03198294  0.03191489  0.03184713  0.03177966  0.03171247  0.03164557  0.03157895  0.03151261  0.03144654  0.03138075  0.03131524  0.03125     0.03118503  0.03112033  0.0310559   0.03099174  0.03092784  0.0308642   0.03080082  0.0307377   0.03067485  0.03061224  0.0305499   0.0304878   0.03042596  0.03036437  0.03030303  0.03024194  0.03018109  0.03012048  0.03006012  0.03        0.02994012  0.02988048  0.02982107  0.0297619   0.02970297  0.02964427  0.0295858   0.02952756  0.02946955  0.02941176  0.02935421  0.02929688  0.02923977  0.02918288  0.02912621  0.02906977  0.02901354  0.02895753  0.02890173  0.02884615  0.02879079  0.02873563  0.02868069  0.02862595  0.02857143  0.02851711  0.028463    0.02840909  0.02835539  0.02830189  0.02824859  0.02819549  0.02814259  0.02808989  0.02803738] 

AP for person = 0.1150

 pottedplant
im_name = 004712_gblur_r5
max IoU = 0.504648358095

 pottedplant
im_name = 006307_gblur_r5
max IoU = 0.081834348394

recall =  [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5]
precision =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.00208333  0.002079    0.00207469  0.00207039  0.00206612  0.00206186  0.00205761  0.00205339  0.00204918  0.00204499  0.00204082  0.00203666  0.00203252  0.0020284   0.00202429  0.0020202   0.00201613  0.00201207  0.00200803  0.00200401  0.002       0.00199601  0.00199203  0.00198807  0.00198413  0.0019802   0.00197628  0.00197239] 

AP for pottedplant = 0.0011

 sheep
im_name = 004072_gblur_r5
max IoU = 0.0616641901932

 sheep
im_name = 000458_gblur_r5
max IoU = 0.554366760224

 sheep
im_name = 004646_gblur_r5
max IoU = 0.0593372085183

recall =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333]
precision =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.00763359  0.00757576  0.0075188   0.00746269  0.00740741  0.00735294  0.00729927  0.00724638  0.00719424  0.00714286  0.0070922   0.00704225  0.00699301  0.00694444  0.00689655  0.00684932  0.00680272  0.00675676  0.00671141  0.00666667  0.00662252  0.00657895  0.00653595  0.00649351  0.00645161  0.00641026  0.00636943  0.00632911  0.00628931  0.00625     0.00621118  0.00617284  0.00613497  0.00609756  0.00606061  0.0060241   0.00598802  0.00595238  0.00591716  0.00588235  0.00584795  0.00581395  0.00578035  0.00574713  0.00571429  0.00568182  0.00564972  0.00561798  0.00558659  0.00555556  0.00552486  0.00549451  0.00546448  0.00543478  0.00540541  0.00537634  0.00534759  0.00531915  0.00529101  0.00526316  0.0052356   0.00520833  0.00518135  0.00515464  0.00512821  0.00510204  0.00507614  0.00505051  0.00502513  0.005       0.00497512  0.0049505   0.00492611  0.00490196  0.00487805  0.00485437  0.00483092  0.00480769  0.00478469  0.0047619   0.00473934  0.00471698  0.00469484  0.0046729   0.00465116  0.00462963  0.00460829  0.00458716  0.00456621  0.00454545  0.00452489  0.0045045   0.0044843   0.00446429  0.00444444  0.00442478  0.00440529  0.00438596  0.00436681  0.00434783  0.004329    0.00431034  0.00429185  0.0042735   0.00425532  0.00423729  0.00421941  0.00420168  0.0041841   0.00416667  0.00414938  0.00413223  0.00411523  0.00409836  0.00408163  0.00406504  0.00404858  0.00403226  0.00401606  0.004       0.00398406  0.00396825  0.00395257  0.00393701  0.00392157  0.00390625  0.00389105  0.00387597  0.003861    0.00384615  0.00383142  0.00381679  0.00380228  0.00378788  0.00377358  0.0037594   0.00374532  0.00373134  0.00371747  0.0037037   0.00369004  0.00367647  0.003663    0.00364964  0.00363636  0.00362319  0.00361011  0.00359712  0.00358423  0.00357143  0.00355872  0.0035461   0.00353357  0.00352113  0.00350877  0.0034965   0.00348432  0.00347222  0.00346021  0.00344828  0.00343643  0.00342466  0.00341297  0.00340136  0.00338983  0.00337838  0.003367    0.0033557   0.00334448  0.00333333  0.00332226  0.00331126  0.00330033  0.00328947  0.00327869  0.00326797  0.00325733  0.00324675  0.00323625  0.00322581] 

AP for sheep = 0.0028

 sofa
im_name = 004096_gblur_r5
max IoU = 0.6509509877

 sofa
im_name = 008395_gblur_r5
max IoU = 0.555769611292

 sofa
im_name = 007785_gblur_r5
max IoU = 0.270447354744

 sofa
im_name = 000658_gblur_r5
max IoU = 0.3110943643

 sofa
im_name = 008543_gblur_r5
max IoU = 0.262381967285

 sofa
im_name = 006307_gblur_r5
max IoU = 0.233369468809

recall =  [ 0.16666667  0.16666667  0.16666667  0.16666667  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333]
precision =  [ 1.          0.5         0.33333333  0.25        0.4         0.33333333  0.28571429  0.25        0.22222222  0.2         0.18181818  0.16666667  0.15384615  0.14285714  0.13333333  0.125       0.11764706  0.11111111  0.10526316  0.1         0.0952381   0.09090909  0.08695652  0.08333333  0.08        0.07692308  0.07407407  0.07142857  0.06896552  0.06666667  0.06451613  0.0625      0.06060606  0.05882353  0.05714286  0.05555556  0.05405405  0.05263158  0.05128205  0.05        0.04878049  0.04761905  0.04651163  0.04545455  0.04444444  0.04347826  0.04255319  0.04166667  0.04081633  0.04        0.03921569  0.03846154  0.03773585  0.03703704  0.03636364  0.03571429  0.03508772  0.03448276  0.03389831  0.03333333  0.03278689  0.03225806  0.03174603  0.03125     0.03076923  0.03030303  0.02985075  0.02941176  0.02898551  0.02857143  0.02816901  0.02777778  0.02739726  0.02702703  0.02666667  0.02631579  0.02597403  0.02564103  0.02531646  0.025       0.02469136  0.02439024  0.02409639  0.02380952  0.02352941  0.02325581  0.02298851  0.02272727  0.02247191  0.02222222  0.02197802  0.02173913  0.02150538  0.0212766   0.02105263  0.02083333  0.02061856  0.02040816  0.02020202  0.02        0.01980198  0.01960784  0.01941748  0.01923077  0.01904762  0.01886792  0.01869159  0.01851852  0.01834862  0.01818182  0.01801802  0.01785714  0.01769912  0.01754386  0.0173913   0.01724138  0.01709402  0.01694915  0.01680672  0.01666667  0.01652893  0.01639344  0.01626016  0.01612903  0.016       0.01587302  0.01574803  0.015625    0.01550388  0.01538462  0.01526718  0.01515152  0.01503759  0.01492537  0.01481481  0.01470588  0.01459854  0.01449275  0.01438849  0.01428571  0.0141844   0.01408451  0.01398601  0.01388889  0.0137931   0.01369863  0.01360544  0.01351351  0.01342282  0.01333333  0.01324503  0.01315789  0.0130719   0.01298701  0.01290323  0.01282051  0.01273885  0.01265823  0.01257862  0.0125      0.01242236  0.01234568  0.01226994  0.01219512  0.01212121  0.01204819  0.01197605  0.01190476  0.01183432  0.01176471  0.01169591  0.01162791  0.01156069  0.01149425  0.01142857  0.01136364  0.01129944  0.01123596  0.01117318  0.01111111  0.01104972  0.01098901  0.01092896  0.01086957  0.01081081  0.01075269  0.01069519  0.0106383   0.01058201  0.01052632  0.0104712   0.01041667  0.01036269] 

AP for sofa = 0.2545

 train
im_name = 005011_gblur_r5
max IoU = 0.403575519831

 train
im_name = 008065_gblur_r5
max IoU = 0.639745914689

 train
im_name = 005172_gblur_r5
max IoU = 0.710447056686

recall =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667]
precision =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.01075269  0.0106383   0.01052632  0.01041667  0.01030928  0.01020408  0.01010101  0.01        0.00990099  0.00980392  0.00970874  0.00961538  0.00952381  0.00943396  0.00934579  0.00925926  0.00917431  0.00909091  0.00900901  0.00892857  0.01769912  0.01754386  0.0173913   0.01724138  0.01709402  0.01694915  0.01680672  0.01666667] 

AP for train = 0.0113

 tvmonitor
im_name = 006688_gblur_r5
max IoU = 0.491480344783

 tvmonitor
im_name = 001704_gblur_r5
max IoU = 0.734550906271

 tvmonitor
im_name = 006307_gblur_r5
max IoU = 0.0812602212112

recall =  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25]
precision =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.03448276  0.03333333  0.03225806  0.03125     0.03030303  0.02941176  0.02857143  0.02777778  0.02702703  0.02631579  0.02564103  0.025       0.02439024  0.02380952  0.02325581  0.02272727  0.02222222  0.02173913  0.0212766   0.02083333  0.02040816  0.02        0.01960784  0.01923077  0.01886792  0.01851852  0.01818182  0.01785714  0.01754386  0.01724138  0.01694915  0.01666667  0.01639344  0.01612903  0.01587302  0.015625    0.01538462  0.01515152  0.01492537  0.01470588  0.01449275  0.01428571  0.01408451  0.01388889  0.01369863  0.01351351  0.01333333  0.01315789  0.01298701  0.01282051  0.01265823  0.0125      0.01234568  0.01219512  0.01204819  0.01190476  0.01176471  0.01162791  0.01149425  0.01136364  0.01123596  0.01111111  0.01098901  0.01086957  0.01075269  0.0106383   0.01052632  0.01041667  0.01030928  0.01020408  0.01010101  0.01        0.00990099  0.00980392  0.00970874  0.00961538  0.00952381  0.00943396  0.00934579  0.00925926  0.00917431  0.00909091  0.00900901  0.00892857  0.00884956  0.00877193  0.00869565  0.00862069  0.00854701  0.00847458  0.00840336  0.00833333  0.00826446  0.00819672  0.00813008  0.00806452  0.008       0.00793651  0.00787402  0.0078125   0.00775194  0.00769231  0.00763359  0.00757576  0.0075188   0.00746269  0.00740741  0.00735294  0.00729927  0.00724638  0.00719424  0.00714286  0.0070922   0.00704225  0.00699301  0.00694444  0.00689655  0.00684932  0.00680272  0.00675676  0.00671141  0.00666667  0.00662252  0.00657895  0.00653595  0.00649351  0.00645161  0.00641026  0.00636943  0.00632911  0.00628931  0.00625     0.00621118  0.00617284  0.00613497  0.00609756  0.00606061  0.0060241   0.00598802  0.00595238  0.00591716  0.00588235  0.00584795  0.00581395  0.00578035  0.00574713  0.00571429  0.00568182  0.00564972  0.00561798  0.00558659  0.00555556  0.00552486  0.00549451  0.00546448  0.00543478  0.00540541  0.00537634  0.00534759  0.00531915  0.00529101  0.00526316  0.0052356   0.00520833  0.00518135  0.00515464  0.00512821  0.00510204  0.00507614  0.00505051  0.00502513  0.005       0.00497512  0.0049505   0.00492611  0.00490196  0.00487805  0.00485437  0.00483092  0.00480769  0.00478469  0.0047619   0.00473934  0.00471698  0.00469484  0.0046729   0.00465116  0.00462963  0.00460829  0.00458716  0.00456621  0.00454545  0.00452489  0.0045045   0.0044843   0.00446429  0.00444444  0.00442478  0.00440529  0.00438596  0.00436681  0.00434783  0.004329    0.00431034  0.00429185  0.0042735   0.00425532  0.00423729  0.00421941  0.00420168  0.0041841   0.00416667  0.00414938  0.00413223  0.00411523  0.00409836  0.00408163  0.00406504  0.00404858  0.00403226  0.00401606  0.004       0.00398406  0.00396825  0.00395257  0.00393701  0.00392157  0.00390625  0.00389105  0.00387597  0.003861    0.00384615  0.00383142  0.00381679  0.00380228  0.00378788  0.00377358  0.0037594   0.00374532  0.00373134  0.00371747  0.0037037   0.00369004  0.00367647  0.003663    0.00364964  0.00363636  0.00362319  0.00361011  0.00359712  0.00358423  0.00357143  0.00355872  0.0035461   0.00353357  0.00352113  0.00350877  0.0034965   0.00348432  0.00347222  0.00346021  0.00344828  0.00343643  0.00342466  0.00341297  0.00340136  0.00338983  0.00337838  0.003367    0.0033557   0.00334448  0.00333333  0.00332226  0.00331126  0.00330033  0.00328947  0.00327869  0.00326797  0.00325733  0.00324675  0.00323625  0.00322581  0.00321543  0.00320513  0.00319489  0.00318471  0.0031746   0.00316456  0.00315457  0.00314465  0.0031348   0.003125    0.00311526  0.00310559  0.00309598  0.00308642  0.00307692  0.00306748  0.0030581   0.00304878  0.00303951  0.0030303   0.00302115  0.00301205  0.003003    0.00299401  0.00298507  0.00297619  0.00296736  0.00295858  0.00294985  0.00294118  0.00293255  0.00292398  0.00291545  0.00290698  0.00289855  0.00289017  0.00288184  0.00287356  0.00286533  0.00285714  0.002849    0.00284091  0.00283286  0.00282486  0.0028169   0.00280899  0.00280112  0.0027933   0.00278552  0.00277778  0.00277008  0.00276243  0.00275482  0.00274725  0.00273973  0.00273224  0.0027248   0.00271739  0.00271003  0.0027027   0.00269542  0.00268817  0.00268097  0.0026738   0.00266667  0.00265957  0.00265252  0.0026455   0.00263852  0.00263158  0.00262467  0.0026178   0.00261097  0.00260417  0.0025974   0.00259067  0.00258398  0.00257732  0.00257069  0.0025641   0.00255754  0.00255102  0.00254453  0.00253807  0.00253165  0.00252525  0.00251889  0.00251256  0.00250627  0.0025      0.00249377  0.00248756  0.00248139  0.00247525  0.00246914  0.00246305  0.002457    0.00245098  0.00244499  0.00243902  0.00243309  0.00242718  0.00242131  0.00241546  0.00240964  0.00240385  0.00239808  0.00239234  0.00238663  0.00238095  0.0023753   0.00236967  0.00236407  0.00235849  0.00235294  0.00234742  0.00234192  0.00233645  0.002331    0.00232558  0.00232019  0.00231481  0.00230947  0.00230415  0.00229885  0.00229358  0.00228833  0.00228311  0.0022779   0.00227273  0.00226757  0.00226244  0.00225734  0.00225225  0.00224719  0.00224215  0.00223714  0.00223214  0.00222717  0.00222222  0.00221729  0.00221239  0.00220751  0.00220264  0.0021978   0.00219298  0.00218818  0.00218341  0.00217865  0.00217391  0.0021692   0.0021645   0.00215983  0.00215517  0.00215054  0.00214592  0.00214133  0.00213675  0.0021322   0.00212766  0.00212314  0.00211864  0.00211416  0.0021097   0.00210526  0.00210084  0.00209644  0.00209205  0.00208768  0.00208333  0.002079    0.00207469  0.00207039  0.00206612  0.00206186  0.00205761  0.00205339  0.00204918  0.00204499  0.00204082  0.00203666  0.00203252  0.0020284   0.00202429  0.0020202   0.00201613  0.00201207  0.00200803  0.00200401  0.002       0.00199601  0.00199203  0.00198807  0.00198413  0.0019802   0.00197628  0.00197239  0.0019685   0.00196464  0.00196078  0.00195695  0.00195312  0.00194932  0.00194553  0.00194175  0.00193798  0.00193424  0.0019305   0.00192678  0.00192308  0.00191939  0.00191571  0.00191205  0.0019084   0.00190476  0.00190114  0.00189753  0.00189394  0.00189036  0.00188679  0.00188324  0.0018797   0.00187617  0.00187266  0.00186916  0.00186567  0.0018622 ] 

AP for tvmonitor = 0.0094

Mean AP = 0.0483
~~~~~~~~
Results:
0.000
0.091
0.011
0.000
0.000
0.021
0.208
0.074
0.030
0.000
0.000
0.021
0.010
0.107
0.115
0.001
0.003
0.255
0.011
0.009
0.048
~~~~~~~~

--------------------------------------------------------------
Results computed with the **unofficial** Python eval code.
Results should be very close to the official MATLAB eval code.
Recompute with `./tools/reval.py --matlab ...` for your paper.
-- Thanks, The Management
--------------------------------------------------------------
27.97user 7.88system 0:35.74elapsed 100%CPU (0avgtext+0avgdata 1771812maxresident)k
0inputs+1336outputs (0major+312161minor)pagefaults 0swaps
