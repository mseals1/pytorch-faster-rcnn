+ echo Logging output to experiments/logs/test_vgg16_voc_2007_trainval_.txt.2018-05-24_18-43-27
Logging output to experiments/logs/test_vgg16_voc_2007_trainval_.txt.2018-05-24_18-43-27
+ set +x
+ [[ ! -z '' ]]
+ CUDA_VISIBLE_DEVICES=0
+ time python ./tools/test_net.py --imdb voc_2007_test --model output/vgg16/voc_2007_trainval/default/vgg16_faster_rcnn_iter_70000.pth --cfg experiments/cfgs/vgg16.yml --net vgg16 --set ANCHOR_SCALES '[8,16,32]' ANCHOR_RATIOS '[0.5,1,2]'
/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/colors.py:680: MatplotlibDeprecationWarning: The is_string_like function was deprecated in version 2.1.
  not cbook.is_string_like(colors[0]):
Called with args:
Namespace(cfg_file='experiments/cfgs/vgg16.yml', comp_mode=False, imdb_name='voc_2007_test', max_per_image=100, model='output/vgg16/voc_2007_trainval/default/vgg16_faster_rcnn_iter_70000.pth', net='vgg16', set_cfgs=['ANCHOR_SCALES', '[8,16,32]', 'ANCHOR_RATIOS', '[0.5,1,2]'], tag='')
Using config:
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32],
 'DATA_DIR': '/home/ubuntu/pytorch-faster-rcnn/data',
 'EXP_DIR': 'vgg16',
 'MATLAB': 'matlab',
 'MOBILENET': {'DEPTH_MULTIPLIER': 1.0,
               'FIXED_LAYERS': 5,
               'REGU_DEPTH': False,
               'WEIGHT_DECAY': 4e-05},
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'RESNET': {'FIXED_BLOCKS': 1, 'MAX_POOL': False},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/pytorch-faster-rcnn',
 'RPN_CHANNELS': 512,
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'MODE': 'nms',
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'gt',
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'RPN_TOP_N': 5000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': False,
           'BATCH_SIZE': 256,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'BIAS_DECAY': False,
           'DISPLAY': 20,
           'DOUBLE_BIAS': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'GAMMA': 0.1,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'LEARNING_RATE': 0.001,
           'MAX_SIZE': 1000,
           'MOMENTUM': 0.9,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_ITERS': 5000,
           'SNAPSHOT_KEPT': 3,
           'SNAPSHOT_PREFIX': 'vgg16_faster_rcnn',
           'STEPSIZE': [30000],
           'SUMMARY_INTERVAL': 180,
           'TRUNCATED': False,
           'USE_ALL_GT': True,
           'USE_FLIPPED': True,
           'USE_GT': False,
           'WEIGHT_DECAY': 0.0001},
 'USE_GPU_NMS': True}
Loading model check point from output/vgg16/voc_2007_trainval/default/vgg16_faster_rcnn_iter_70000.pth
Loaded.
/home/ubuntu/pytorch-faster-rcnn/tools/../lib/nets/network.py:245: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  rpn_cls_prob_reshape = F.softmax(rpn_cls_score_reshape)
/home/ubuntu/pytorch-faster-rcnn/tools/../lib/nets/network.py:280: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  cls_prob = F.softmax(cls_score)
im_detect: 1/64 0.992s 0.004s
im_detect: 2/64 0.643s 0.004s
im_detect: 3/64 0.525s 0.003s
im_detect: 4/64 0.470s 0.004s
im_detect: 5/64 0.437s 0.003s
im_detect: 6/64 0.413s 0.004s
im_detect: 7/64 0.394s 0.003s
im_detect: 8/64 0.384s 0.003s
im_detect: 9/64 0.374s 0.003s
im_detect: 10/64 0.365s 0.003s
im_detect: 11/64 0.358s 0.003s
im_detect: 12/64 0.351s 0.003s
im_detect: 13/64 0.347s 0.003s
im_detect: 14/64 0.343s 0.003s
im_detect: 15/64 0.339s 0.003s
im_detect: 16/64 0.338s 0.003s
im_detect: 17/64 0.337s 0.003s
im_detect: 18/64 0.333s 0.003s
im_detect: 19/64 0.332s 0.003s
im_detect: 20/64 0.329s 0.003s
im_detect: 21/64 0.325s 0.003s
im_detect: 22/64 0.324s 0.003s
im_detect: 23/64 0.324s 0.003s
im_detect: 24/64 0.323s 0.003s
im_detect: 25/64 0.321s 0.003s
im_detect: 26/64 0.320s 0.003s
im_detect: 27/64 0.319s 0.003s
im_detect: 28/64 0.318s 0.003s
im_detect: 29/64 0.317s 0.003s
im_detect: 30/64 0.316s 0.003s
im_detect: 31/64 0.316s 0.003s
im_detect: 32/64 0.315s 0.003s
im_detect: 33/64 0.314s 0.003s
im_detect: 34/64 0.314s 0.003s
im_detect: 35/64 0.313s 0.003s
im_detect: 36/64 0.312s 0.003s
im_detect: 37/64 0.312s 0.003s
im_detect: 38/64 0.311s 0.003s
im_detect: 39/64 0.309s 0.003s
im_detect: 40/64 0.309s 0.003s
im_detect: 41/64 0.309s 0.003s
im_detect: 42/64 0.308s 0.003s
im_detect: 43/64 0.308s 0.003s
im_detect: 44/64 0.307s 0.003s
im_detect: 45/64 0.307s 0.003s
im_detect: 46/64 0.307s 0.003s
im_detect: 47/64 0.306s 0.003s
im_detect: 48/64 0.306s 0.003s
im_detect: 49/64 0.306s 0.003s
im_detect: 50/64 0.305s 0.003s
im_detect: 51/64 0.305s 0.003s
im_detect: 52/64 0.304s 0.003s
im_detect: 53/64 0.304s 0.003s
im_detect: 54/64 0.304s 0.003s
im_detect: 55/64 0.303s 0.003s
im_detect: 56/64 0.303s 0.003s
im_detect: 57/64 0.303s 0.003s
im_detect: 58/64 0.303s 0.003s
im_detect: 59/64 0.302s 0.003s
im_detect: 60/64 0.302s 0.003s
im_detect: 61/64 0.302s 0.003s
im_detect: 62/64 0.302s 0.003s
im_detect: 63/64 0.302s 0.003s
im_detect: 64/64 0.301s 0.003s
Evaluating detections
Writing aeroplane VOC results file
Writing bicycle VOC results file
Writing bird VOC results file
Writing boat VOC results file
Writing bottle VOC results file
Writing bus VOC results file
Writing car VOC results file
Writing cat VOC results file
Writing chair VOC results file
Writing cow VOC results file
Writing diningtable VOC results file
Writing dog VOC results file
Writing horse VOC results file
Writing motorbike VOC results file
Writing person VOC results file
Writing pottedplant VOC results file
Writing sheep VOC results file
Writing sofa VOC results file
Writing train VOC results file
Writing tvmonitor VOC results file
VOC07 metric? Yes
Reading annotation for 1/64
Saving cached annotations to /home/ubuntu/pytorch-faster-rcnn/data/VOCdevkit2007/VOC2007/ImageSets/Main/test.txt_annots.pkl
/home/ubuntu/pytorch-faster-rcnn/tools/../lib/datasets/voc_eval.py:223: RuntimeWarning: invalid value encountered in true_divide
  rec = tp / float(npos)

recall =  [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]
precision =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 

/home/ubuntu/pytorch-faster-rcnn/tools/../lib/datasets/voc_eval.py:49: RuntimeWarning: invalid value encountered in greater_equal
  if np.sum(rec >= t) == 0:
AP for aeroplane = 0.0000

 bicycle
im_name = 007529_gblur_r3
max IoU = 0.779430012758

 bicycle
im_name = 007010_gblur_r3
max IoU = 0.707999756695

 bicycle
im_name = 006775_gblur_r3
max IoU = 0.232258069009

 bicycle
im_name = 002325_gblur_r3
max IoU = 0.534727647184

recall =  [ 0.16666667  0.16666667  0.16666667  0.16666667  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.5         0.5         0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667]
precision =  [ 1.          0.5         0.33333333  0.25        0.4         0.33333333  0.28571429  0.25        0.22222222  0.2         0.18181818  0.16666667  0.15384615  0.14285714  0.13333333  0.125       0.11764706  0.11111111  0.10526316  0.1         0.0952381   0.09090909  0.08695652  0.08333333  0.08        0.07692308  0.07407407  0.07142857  0.06896552  0.06666667  0.06451613  0.0625      0.06060606  0.05882353  0.05714286  0.05555556  0.05405405  0.05263158  0.05128205  0.05        0.04878049  0.04761905  0.04651163  0.04545455  0.04444444  0.04347826  0.04255319  0.04166667  0.04081633  0.04        0.03921569  0.03846154  0.03773585  0.03703704  0.03636364  0.03571429  0.03508772  0.03448276  0.03389831  0.03333333  0.03278689  0.03225806  0.03174603  0.03125     0.03076923  0.03030303  0.02985075  0.02941176  0.02898551  0.02857143  0.02816901  0.02777778  0.02739726  0.02702703  0.02666667  0.02631579  0.02597403  0.02564103  0.02531646  0.025       0.02469136  0.02439024  0.02409639  0.02380952  0.02352941  0.02325581  0.02298851  0.02272727  0.02247191  0.02222222  0.02197802  0.02173913  0.02150538  0.0212766   0.02105263  0.02083333  0.02061856  0.02040816  0.02020202  0.02        0.01980198  0.01960784  0.01941748  0.01923077  0.01904762  0.01886792  0.01869159  0.01851852  0.01834862  0.01818182  0.01801802  0.01785714  0.01769912  0.01754386  0.0173913   0.01724138  0.01709402  0.01694915  0.01680672  0.01666667  0.01652893  0.01639344  0.01626016  0.01612903  0.016       0.01587302  0.01574803  0.015625    0.01550388  0.01538462  0.01526718  0.01515152  0.01503759  0.01492537  0.01481481  0.01470588  0.01459854  0.01449275  0.01438849  0.01428571  0.0141844   0.01408451  0.01398601  0.01388889  0.0137931   0.01369863  0.01360544  0.01351351  0.01342282  0.01333333  0.01324503  0.01315789  0.0130719   0.01298701  0.01290323  0.01282051  0.01273885  0.01265823  0.01257862  0.0125      0.01242236  0.01234568  0.01226994  0.01219512  0.01212121  0.01204819  0.01197605  0.01190476  0.01183432  0.01176471  0.01169591  0.01162791  0.01156069  0.01149425  0.01142857  0.01136364  0.01129944  0.01123596  0.01117318  0.01111111  0.01104972  0.01098901  0.01092896  0.01086957  0.01081081  0.01075269  0.01069519  0.0106383   0.01058201  0.01052632  0.0104712   0.01041667  0.01554404  0.01546392  0.02051282  0.02040816  0.02030457  0.02020202  0.0201005   0.02        0.0199005   0.01980198  0.01970443  0.01960784  0.0195122   0.01941748  0.01932367  0.01923077  0.01913876  0.01904762  0.01895735  0.01886792  0.01877934  0.01869159  0.01860465  0.01851852  0.01843318  0.01834862  0.01826484  0.01818182  0.01809955  0.01801802  0.01793722  0.01785714  0.01777778  0.01769912  0.01762115  0.01754386  0.01746725  0.0173913   0.01731602  0.01724138  0.01716738  0.01709402  0.01702128  0.01694915  0.01687764  0.01680672  0.0167364   0.01666667  0.01659751  0.01652893  0.01646091  0.01639344  0.01632653  0.01626016  0.01619433  0.01612903  0.01606426  0.016       0.01593625  0.01587302  0.01581028  0.01574803  0.01568627  0.015625    0.0155642   0.01550388  0.01544402  0.01538462] 

AP for bicycle = 0.2601

 bird
im_name = 002400_gblur_r3
max IoU = 0.535592360822

 bird
im_name = 001967_gblur_r3
max IoU = 0.282456140351

 bird
im_name = 007476_gblur_r3
max IoU = 0.320515141913

 bird
im_name = 008118_gblur_r3
max IoU = 0.686925915687

 bird
im_name = 002431_gblur_r3
max IoU = 0.239058633813

 bird
im_name = 003741_gblur_r3
max IoU = 0.168325073324

recall =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.28571429  0.28571429  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143  0.42857143]
precision =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.02777778  0.02702703  0.02631579  0.02564103  0.025       0.02439024  0.02380952  0.02325581  0.02272727  0.02222222  0.02173913  0.0212766   0.02083333  0.02040816  0.02        0.01960784  0.01923077  0.01886792  0.01851852  0.01818182  0.01785714  0.01754386  0.01724138  0.01694915  0.01666667  0.01639344  0.01612903  0.01587302  0.015625    0.01538462  0.01515152  0.01492537  0.01470588  0.01449275  0.01428571  0.01408451  0.01388889  0.02739726  0.02702703  0.04        0.03947368  0.03896104  0.03846154  0.03797468  0.0375      0.03703704  0.03658537  0.03614458  0.03571429  0.03529412  0.03488372  0.03448276  0.03409091  0.03370787  0.03333333  0.03296703  0.0326087   0.03225806  0.03191489  0.03157895  0.03125     0.03092784  0.03061224  0.03030303  0.03        0.02970297  0.02941176  0.02912621  0.02884615  0.02857143  0.02830189  0.02803738  0.02777778  0.02752294  0.02727273  0.02702703  0.02678571  0.02654867  0.02631579  0.02608696  0.02586207  0.02564103  0.02542373  0.02521008  0.025       0.02479339  0.02459016  0.02439024  0.02419355  0.024       0.02380952  0.02362205  0.0234375   0.02325581  0.02307692  0.02290076  0.02272727  0.02255639  0.02238806  0.02222222  0.02205882  0.02189781  0.02173913  0.02158273  0.02142857  0.0212766   0.02112676  0.02097902  0.02083333  0.02068966  0.02054795  0.02040816  0.02027027  0.02013423  0.02        0.01986755  0.01973684  0.01960784  0.01948052  0.01935484  0.01923077  0.01910828  0.01898734  0.01886792  0.01875     0.01863354  0.01851852  0.01840491  0.01829268  0.01818182  0.01807229  0.01796407  0.01785714  0.01775148  0.01764706  0.01754386  0.01744186  0.01734104  0.01724138  0.01714286  0.01704545  0.01694915  0.01685393  0.01675978  0.01666667  0.01657459  0.01648352  0.01639344  0.01630435  0.01621622  0.01612903  0.01604278  0.01595745  0.01587302  0.01578947  0.01570681  0.015625    0.01554404  0.01546392  0.01538462  0.01530612  0.01522843  0.01515152  0.01507538  0.015       0.01492537  0.01485149  0.01477833  0.01470588  0.01463415  0.01456311  0.01449275  0.01442308  0.01435407  0.01428571  0.01421801  0.01415094  0.01408451  0.01401869  0.01395349  0.01388889  0.01382488  0.01376147  0.01369863  0.01363636  0.01357466  0.01351351  0.01345291  0.01339286  0.01333333  0.01327434  0.01321586  0.01315789  0.01310044  0.01304348  0.01298701  0.01293103  0.01287554  0.01282051  0.01276596  0.01271186  0.01265823  0.01260504  0.0125523   0.0125      0.01244813  0.01239669  0.01234568  0.01229508  0.0122449   0.01219512  0.01214575  0.01209677  0.01204819  0.012       0.01195219  0.01190476  0.01185771  0.01181102  0.01176471  0.01171875  0.01167315  0.01162791  0.01158301  0.01153846  0.01149425  0.01145038  0.01140684  0.01136364  0.01132075  0.0112782   0.01123596  0.01119403  0.01115242  0.01111111  0.01107011  0.01102941  0.01098901  0.01094891  0.01090909  0.01086957  0.01083032  0.01079137  0.01075269  0.01071429  0.01067616  0.0106383   0.01060071  0.01056338  0.01052632  0.01048951  0.01045296  0.01041667  0.01038062  0.01034483  0.01030928  0.01027397  0.01023891  0.01020408  0.01016949  0.01013514  0.01010101  0.01006711  0.01003344  0.01        0.00996678  0.00993377  0.00990099  0.00986842  0.00983607  0.00980392  0.00977199  0.00974026  0.00970874  0.00967742  0.0096463   0.00961538  0.00958466  0.00955414  0.00952381  0.00949367  0.00946372  0.00943396  0.00940439  0.009375    0.00934579  0.00931677  0.00928793  0.00925926  0.00923077  0.00920245  0.00917431  0.00914634  0.00911854  0.00909091  0.00906344  0.00903614  0.00900901  0.00898204  0.00895522  0.00892857  0.00890208  0.00887574  0.00884956  0.00882353  0.00879765  0.00877193  0.00874636  0.00872093  0.00869565  0.00867052  0.00864553  0.00862069  0.00859599  0.00857143  0.00854701  0.00852273  0.00849858  0.00847458  0.0084507   0.00842697  0.00840336  0.00837989  0.00835655  0.00833333  0.00831025  0.00828729  0.00826446  0.00824176  0.00821918  0.00819672  0.00817439  0.00815217  0.00813008  0.00810811  0.00808625  0.00806452  0.0080429   0.00802139  0.008       0.00797872  0.00795756  0.00793651  0.00791557  0.00789474  0.00787402  0.0078534   0.0078329   0.0078125   0.00779221  0.00777202  0.00775194  0.00773196  0.00771208  0.00769231  0.00767263  0.00765306  0.00763359  0.00761421  0.00759494  0.00757576  0.00755668  0.00753769  0.0075188   0.0075      0.0074813   0.00746269  0.00744417  0.00742574  0.00740741  0.00738916  0.00737101  0.00735294  0.00733496  0.00731707  0.00729927  0.00728155  0.00726392  0.00724638  0.00722892  0.00721154  0.00719424  0.00717703  0.0071599   0.00714286  0.00712589  0.007109    0.0070922   0.00707547  0.00705882  0.00704225  0.00702576  0.00700935  0.00699301  0.00697674  0.00696056  0.00694444  0.00692841  0.00691244  0.00689655  0.00688073  0.00686499] 

AP for bird = 0.0182

 boat
im_name = 000538_gblur_r3
max IoU = 0.138089957724

 boat
im_name = 003012_gblur_r3
max IoU = 0.0108496072233

 boat
im_name = 002390_gblur_r3
max IoU = 0.463619365902

recall =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
precision =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 

AP for boat = 0.0000

 bottle
im_name = 000762_gblur_r3
max IoU = 0.41755952381

 bottle
im_name = 004712_gblur_r3
max IoU = 0.0930500588978

 bottle
im_name = 004072_gblur_r3
max IoU = 0.0450127977562

recall =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
precision =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 

AP for bottle = 0.0000

 bus
im_name = 002216_gblur_r3
max IoU = 0.622342158041

recall =  [ 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]
precision =  [ 1.          0.5         0.33333333  0.25        0.2         0.16666667  0.14285714  0.125       0.11111111  0.1         0.09090909  0.08333333  0.07692308  0.07142857  0.06666667  0.0625      0.05882353  0.05555556  0.05263158  0.05        0.04761905  0.04545455  0.04347826  0.08333333  0.08        0.07692308  0.07407407  0.07142857  0.06896552  0.06666667  0.06451613  0.0625      0.06060606  0.05882353  0.05714286  0.05555556  0.05405405  0.05263158  0.05128205  0.05        0.04878049  0.04761905  0.04651163  0.04545455  0.04444444  0.04347826  0.04255319  0.04166667  0.04081633  0.04        0.03921569  0.03846154  0.03773585  0.03703704  0.03636364  0.03571429  0.03508772  0.03448276  0.03389831  0.03333333  0.03278689  0.03225806  0.03174603  0.03125     0.03076923  0.03030303  0.02985075  0.02941176  0.02898551  0.02857143  0.02816901  0.02777778  0.02739726  0.02702703  0.02666667  0.02631579  0.02597403  0.02564103  0.02531646  0.025       0.02469136  0.02439024  0.02409639  0.02380952  0.02352941  0.02325581  0.02298851  0.02272727  0.02247191  0.02222222  0.02197802  0.02173913  0.02150538  0.0212766   0.02105263  0.02083333  0.02061856  0.02040816  0.02020202  0.02        0.01980198  0.01960784  0.01941748  0.01923077  0.01904762  0.01886792  0.01869159  0.01851852  0.01834862  0.01818182  0.01801802  0.01785714  0.01769912  0.01754386  0.0173913   0.01724138  0.01709402  0.01694915  0.01680672  0.01666667  0.01652893  0.01639344  0.01626016  0.01612903  0.016       0.01587302  0.01574803  0.015625    0.01550388  0.01538462  0.01526718  0.01515152  0.01503759  0.01492537  0.01481481  0.01470588  0.01459854  0.01449275  0.01438849  0.01428571  0.0141844   0.01408451  0.01398601  0.01388889  0.0137931   0.01369863  0.01360544  0.01351351  0.01342282  0.01333333  0.01324503  0.01315789  0.0130719   0.01298701  0.01290323  0.01282051  0.01273885  0.01265823  0.01257862  0.0125      0.01242236  0.01234568  0.01226994  0.01219512  0.01212121  0.01204819  0.01197605  0.01190476  0.01183432  0.01176471  0.01169591  0.01162791  0.01156069  0.01149425  0.01142857  0.01136364  0.01129944  0.01123596  0.01117318  0.01111111  0.01104972  0.01098901  0.01092896  0.01086957  0.01081081  0.01075269  0.01069519  0.0106383   0.01058201  0.01052632  0.0104712   0.01041667  0.01036269  0.01030928  0.01025641  0.01020408  0.01015228  0.01010101  0.01005025  0.01        0.00995025  0.00990099  0.00985222  0.00980392  0.0097561   0.00970874  0.00966184  0.00961538  0.00956938  0.00952381  0.00947867  0.00943396  0.00938967  0.00934579  0.00930233  0.00925926  0.00921659  0.00917431  0.00913242  0.00909091  0.00904977  0.00900901  0.00896861  0.00892857  0.00888889  0.00884956  0.00881057] 

AP for bus = 0.5833

 car
im_name = 005105_gblur_r3
max IoU = 0.731697939874

 car
im_name = 006481_gblur_r3
max IoU = 0.871885012803

 car
im_name = 003701_gblur_r3
max IoU = 0.786128415846

 car
im_name = 000883_gblur_r3
max IoU = 0.586183911153

 car
im_name = 001283_gblur_r3
max IoU = 0.656341260422

recall =  [ 0.16666667  0.16666667  0.33333333  0.33333333  0.33333333  0.33333333  0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.5         0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333  0.83333333]
precision =  [ 1.          0.5         0.66666667  0.5         0.4         0.33333333  0.42857143  0.375       0.33333333  0.3         0.27272727  0.25        0.23076923  0.21428571  0.2         0.1875      0.17647059  0.16666667  0.15789474  0.15        0.14285714  0.13636364  0.13043478  0.125       0.12        0.11538462  0.11111111  0.10714286  0.10344828  0.1         0.09677419  0.09375     0.09090909  0.08823529  0.08571429  0.08333333  0.08108108  0.07894737  0.07692308  0.075       0.07317073  0.07142857  0.06976744  0.06818182  0.06666667  0.06521739  0.06382979  0.0625      0.06122449  0.06        0.05882353  0.05769231  0.05660377  0.05555556  0.05454545  0.05357143  0.05263158  0.05172414  0.05084746  0.05        0.04918033  0.0483871   0.04761905  0.046875    0.04615385  0.04545455  0.04477612  0.04411765  0.04347826  0.04285714  0.04225352  0.04166667  0.04109589  0.04054054  0.04        0.03947368  0.03896104  0.03846154  0.03797468  0.0375      0.03703704  0.03658537  0.03614458  0.03571429  0.03529412  0.03488372  0.03448276  0.03409091  0.03370787  0.03333333  0.03296703  0.0326087   0.03225806  0.03191489  0.03157895  0.03125     0.03092784  0.03061224  0.03030303  0.03        0.02970297  0.02941176  0.02912621  0.02884615  0.02857143  0.02830189  0.02803738  0.02777778  0.02752294  0.02727273  0.02702703  0.02678571  0.02654867  0.02631579  0.02608696  0.02586207  0.02564103  0.02542373  0.02521008  0.025       0.02479339  0.02459016  0.02439024  0.02419355  0.024       0.02380952  0.02362205  0.0234375   0.02325581  0.02307692  0.02290076  0.02272727  0.02255639  0.02238806  0.02222222  0.02205882  0.02189781  0.02173913  0.02158273  0.02142857  0.0212766   0.02112676  0.02097902  0.02083333  0.02068966  0.02054795  0.02040816  0.02027027  0.02013423  0.02        0.01986755  0.01973684  0.01960784  0.01948052  0.01935484  0.01923077  0.01910828  0.01898734  0.01886792  0.01875     0.01863354  0.01851852  0.01840491  0.01829268  0.01818182  0.01807229  0.01796407  0.01785714  0.01775148  0.01764706  0.01754386  0.01744186  0.01734104  0.01724138  0.01714286  0.01704545  0.01694915  0.01685393  0.01675978  0.01666667  0.01657459  0.01648352  0.01639344  0.01630435  0.01621622  0.01612903  0.01604278  0.01595745  0.01587302  0.01578947  0.01570681  0.015625    0.01554404  0.01546392  0.01538462  0.01530612  0.01522843  0.01515152  0.01507538  0.015       0.01492537  0.01485149  0.01477833  0.01470588  0.01463415  0.01456311  0.01932367  0.01923077  0.01913876  0.01904762  0.01895735  0.01886792  0.01877934  0.01869159  0.01860465  0.01851852  0.01843318  0.01834862  0.01826484  0.01818182  0.01809955  0.01801802  0.01793722  0.01785714  0.01777778  0.02212389  0.02202643  0.02192982  0.02183406  0.02173913  0.02164502  0.02155172  0.02145923  0.02136752  0.0212766   0.02118644  0.02109705  0.0210084   0.0209205   0.02083333  0.02074689  0.02066116  0.02057613  0.0204918   0.02040816  0.0203252   0.02024291  0.02016129  0.02008032  0.02        0.01992032  0.01984127  0.01976285  0.01968504  0.01960784  0.01953125  0.01945525  0.01937984  0.01930502  0.01923077  0.01915709  0.01908397  0.01901141  0.01893939  0.01886792  0.01879699  0.01872659  0.01865672  0.01858736  0.01851852  0.01845018  0.01838235  0.01831502  0.01824818  0.01818182  0.01811594  0.01805054  0.01798561  0.01792115  0.01785714  0.01779359  0.0177305   0.01766784  0.01760563  0.01754386  0.01748252  0.0174216   0.01736111  0.01730104  0.01724138  0.01718213  0.01712329  0.01706485  0.0170068   0.01694915  0.01689189  0.01683502  0.01677852  0.01672241  0.01666667  0.0166113   0.01655629  0.01650165  0.01644737  0.01639344  0.01633987  0.01628664  0.01623377  0.01618123  0.01612903  0.01607717  0.01602564  0.01597444] 

AP for car = 0.3870

 cat
im_name = 006688_gblur_r3
max IoU = 0.739237392017

 cat
im_name = 007360_gblur_r3
max IoU = 0.46683767405

 cat
im_name = 006801_gblur_r3
max IoU = 0.562890987654

 cat
im_name = 008110_gblur_r3
max IoU = 0.445132974179

 cat
im_name = 000658_gblur_r3
max IoU = 0.32720111114

recall =  [ 0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 ]
precision =  [ 1.          0.5         0.33333333  0.25        0.2         0.16666667  0.14285714  0.125       0.11111111  0.1         0.09090909  0.08333333  0.07692308  0.07142857  0.13333333  0.125       0.11764706  0.11111111  0.10526316  0.1         0.0952381   0.09090909  0.08695652  0.08333333  0.08        0.07692308  0.07407407  0.07142857  0.06896552  0.06666667  0.06451613  0.0625      0.06060606  0.05882353  0.05714286  0.05555556  0.05405405  0.05263158  0.05128205  0.05        0.04878049  0.04761905  0.04651163  0.04545455  0.04444444  0.04347826  0.04255319  0.04166667  0.04081633  0.04        0.03921569  0.03846154  0.03773585  0.03703704  0.03636364  0.03571429  0.03508772  0.03448276  0.03389831  0.03333333  0.03278689  0.03225806  0.03174603  0.03125     0.03076923  0.03030303  0.02985075  0.02941176  0.02898551  0.02857143  0.02816901  0.02777778  0.02739726  0.02702703  0.02666667  0.02631579  0.02597403  0.02564103  0.02531646  0.025       0.02469136  0.02439024  0.02409639  0.02380952  0.02352941  0.02325581  0.02298851  0.02272727  0.02247191  0.02222222  0.02197802  0.02173913  0.02150538  0.0212766   0.02105263  0.02083333  0.02061856  0.02040816  0.02020202  0.02        0.01980198  0.01960784  0.01941748  0.01923077  0.01904762  0.01886792  0.01869159  0.01851852  0.01834862  0.01818182  0.01801802  0.01785714  0.01769912  0.01754386  0.0173913   0.01724138  0.01709402  0.01694915  0.01680672  0.01666667  0.01652893  0.01639344  0.01626016  0.01612903  0.016       0.01587302  0.01574803  0.015625    0.01550388  0.01538462  0.01526718  0.01515152  0.01503759  0.01492537  0.01481481  0.01470588  0.01459854  0.01449275  0.01438849  0.01428571  0.0141844   0.01408451  0.01398601  0.01388889  0.0137931   0.01369863  0.01360544  0.01351351  0.01342282  0.01333333  0.01324503  0.01315789  0.0130719   0.01298701  0.01290323  0.01282051  0.01273885  0.01265823  0.01257862  0.0125      0.01242236  0.01234568  0.01226994  0.01219512  0.01212121  0.01204819  0.01197605  0.01190476  0.01183432  0.01176471  0.01169591  0.01162791  0.01156069  0.01149425  0.01142857  0.01136364  0.01129944  0.01123596  0.01117318  0.01111111  0.01104972  0.01098901  0.01092896  0.01086957  0.01081081  0.01075269  0.01069519  0.0106383   0.01058201  0.01052632  0.0104712   0.01041667  0.01036269  0.01030928  0.01025641  0.01020408  0.01015228  0.01010101  0.01005025  0.01        0.00995025  0.00990099  0.00985222  0.00980392  0.0097561   0.00970874  0.00966184  0.00961538  0.00956938  0.00952381  0.00947867  0.00943396  0.00938967  0.00934579  0.00930233  0.00925926  0.00921659  0.00917431  0.00913242  0.00909091  0.00904977  0.00900901  0.00896861  0.00892857  0.00888889  0.00884956  0.00881057  0.00877193  0.00873362  0.00869565  0.00865801  0.00862069  0.00858369  0.00854701  0.00851064  0.00847458  0.00843882  0.00840336  0.0083682   0.00833333  0.00829876  0.00826446  0.00823045  0.00819672  0.00816327  0.00813008  0.00809717  0.00806452  0.00803213  0.008       0.00796813  0.00793651  0.00790514  0.00787402  0.00784314  0.0078125   0.0077821   0.00775194  0.00772201  0.00769231  0.00766284  0.00763359  0.00760456  0.00757576  0.00754717  0.0075188   0.00749064  0.00746269  0.00743494  0.00740741  0.00738007  0.00735294  0.00732601  0.00729927  0.00727273  0.00724638  0.00722022  0.00719424  0.00716846  0.00714286  0.00711744  0.0070922   0.00706714  0.00704225  0.00701754  0.00699301  0.00696864  0.00694444  0.00692042  0.00689655  0.00687285  0.00684932  0.00682594  0.00680272  0.00677966  0.00675676  0.00673401  0.00671141  0.00668896  0.00666667  0.00664452  0.00662252  0.00660066  0.00657895  0.00655738  0.00653595  0.00651466  0.00649351  0.00647249  0.00645161  0.00643087  0.00641026  0.00638978  0.00636943  0.00634921  0.00632911  0.00630915  0.00628931  0.00626959  0.00625     0.00623053  0.00621118  0.00619195  0.00617284  0.00615385  0.00613497  0.00611621  0.00609756  0.00607903  0.00606061  0.0060423   0.0060241   0.00600601  0.00598802  0.00597015  0.00595238  0.00593472  0.00591716  0.00589971  0.00588235  0.0058651   0.00584795  0.0058309   0.00581395  0.0057971   0.00578035  0.00576369  0.00574713  0.00573066  0.00571429  0.00569801  0.00568182  0.00566572  0.00564972  0.0056338   0.00561798  0.00560224  0.00558659  0.00557103  0.00555556  0.00554017  0.00552486  0.00550964  0.00549451  0.00547945  0.00546448  0.00544959  0.00543478  0.00542005  0.00540541  0.00539084  0.00537634  0.00536193  0.00534759  0.00533333  0.00531915  0.00530504  0.00529101  0.00527704  0.00526316  0.00524934  0.0052356   0.00522193  0.00520833  0.00519481  0.00518135  0.00516796  0.00515464  0.00514139  0.00512821  0.00511509  0.00510204  0.00508906  0.00507614  0.00506329  0.00505051  0.00503778  0.00502513  0.00501253  0.005       0.00498753  0.00497512  0.00496278  0.0049505   0.00493827  0.00492611  0.004914    0.00490196  0.00488998  0.00487805  0.00486618  0.00485437  0.00484262  0.00483092  0.00481928  0.00480769  0.00479616  0.00478469  0.00477327] 

AP for cat = 0.3091

 chair
im_name = 007785_gblur_r3
max IoU = 0.799714744161

 chair
im_name = 002365_gblur_r3
max IoU = 0.748881556282

 chair
im_name = 000377_gblur_r3
max IoU = 0.755718954248

 chair
im_name = 002724_gblur_r3
max IoU = 0.819240635346

 chair
im_name = 007207_gblur_r3
max IoU = 0.291783544536

 chair
im_name = 008110_gblur_r3
max IoU = 0.553739069825

 chair
im_name = 004712_gblur_r3
max IoU = 0.137397273995

 chair
im_name = 005218_gblur_r3
max IoU = 0.524269795213

 chair
im_name = 005934_gblur_r3
max IoU = 0.764356062424

 chair
im_name = 008543_gblur_r3
max IoU = 0.277961543729

 chair
im_name = 006307_gblur_r3
max IoU = 0.164975202117

recall =  [ 0.      0.      0.      0.0625  0.0625  0.0625  0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.1875  0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.25    0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.3125  0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.375   0.4375  0.4375  0.4375  0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5   ]
precision =  [ 0.          0.          0.          0.25        0.2         0.16666667  0.28571429  0.25        0.22222222  0.2         0.18181818  0.16666667  0.15384615  0.14285714  0.13333333  0.125       0.11764706  0.11111111  0.10526316  0.15        0.14285714  0.13636364  0.13043478  0.125       0.12        0.11538462  0.11111111  0.10714286  0.10344828  0.1         0.09677419  0.09375     0.09090909  0.08823529  0.08571429  0.11111111  0.10810811  0.10526316  0.1025641   0.1         0.09756098  0.0952381   0.09302326  0.09090909  0.08888889  0.08695652  0.08510638  0.08333333  0.08163265  0.08        0.07843137  0.07692308  0.0754717   0.07407407  0.07272727  0.07142857  0.07017544  0.06896552  0.06779661  0.06666667  0.06557377  0.06451613  0.06349206  0.0625      0.06153846  0.06060606  0.05970149  0.05882353  0.05797101  0.05714286  0.05633803  0.05555556  0.05479452  0.05405405  0.05333333  0.05263158  0.05194805  0.05128205  0.05063291  0.05        0.04938272  0.04878049  0.04819277  0.04761905  0.04705882  0.04651163  0.04597701  0.04545455  0.04494382  0.04444444  0.04395604  0.04347826  0.04301075  0.04255319  0.04210526  0.04166667  0.04123711  0.04081633  0.04040404  0.04        0.03960396  0.03921569  0.03883495  0.03846154  0.03809524  0.03773585  0.03738318  0.0462963   0.04587156  0.04545455  0.04504505  0.04464286  0.04424779  0.04385965  0.04347826  0.04310345  0.04273504  0.04237288  0.04201681  0.04166667  0.04132231  0.04098361  0.04065041  0.04032258  0.04        0.03968254  0.03937008  0.0390625   0.03875969  0.03846154  0.03816794  0.03787879  0.03759398  0.03731343  0.03703704  0.04411765  0.04379562  0.04347826  0.04316547  0.04285714  0.04255319  0.04225352  0.04195804  0.04166667  0.04137931  0.04109589  0.04081633  0.04054054  0.04026846  0.04        0.0397351   0.03947368  0.03921569  0.03896104  0.03870968  0.03846154  0.03821656  0.03797468  0.03773585  0.0375      0.03726708  0.03703704  0.03680982  0.03658537  0.03636364  0.03614458  0.03592814  0.03571429  0.03550296  0.03529412  0.03508772  0.03488372  0.03468208  0.03448276  0.03428571  0.03409091  0.03389831  0.03370787  0.03351955  0.03333333  0.03314917  0.03296703  0.03278689  0.0326087   0.03243243  0.03225806  0.03208556  0.03191489  0.03174603  0.03157895  0.03141361  0.03125     0.03108808  0.03092784  0.03076923  0.03061224  0.03045685  0.03030303  0.03015075  0.03        0.02985075  0.03465347  0.03448276  0.03431373  0.03902439  0.03883495  0.03864734  0.03846154  0.03827751  0.03809524  0.03791469  0.03773585  0.03755869  0.03738318  0.0372093   0.03703704  0.03686636  0.03669725  0.03652968  0.03636364  0.0361991   0.03603604  0.03587444  0.03571429  0.03555556  0.03539823  0.03524229  0.03508772  0.0349345   0.03478261  0.03463203  0.03448276  0.03433476  0.03418803  0.03404255  0.03389831  0.03375527  0.03361345  0.0334728   0.03333333  0.03319502  0.03305785  0.03292181  0.03278689  0.03265306  0.03252033  0.03238866  0.03225806  0.03212851  0.032       0.03187251  0.03174603  0.03162055  0.03149606  0.03137255  0.03125     0.0311284   0.03100775  0.03088803  0.03076923  0.03065134  0.03053435  0.03041825  0.03030303  0.03018868  0.03007519  0.02996255  0.02985075  0.02973978  0.02962963  0.0295203   0.02941176  0.02930403  0.02919708  0.02909091  0.02898551  0.02888087  0.02877698  0.02867384  0.02857143  0.02846975  0.02836879  0.02826855  0.02816901  0.02807018  0.02797203  0.02787456  0.02777778  0.02768166  0.02758621  0.02749141  0.02739726  0.02730375  0.02721088  0.02711864  0.02702703  0.02693603  0.02684564  0.02675585  0.02666667  0.02657807  0.02649007  0.02640264  0.02631579  0.02622951  0.02614379  0.02605863  0.02597403  0.02588997  0.02580645  0.02572347  0.02564103  0.02555911  0.02547771  0.02539683  0.02531646  0.02523659  0.02515723  0.02507837  0.025       0.02492212  0.02484472  0.0247678   0.02469136  0.02461538  0.02453988  0.02446483  0.02439024  0.02431611  0.02424242  0.02416918  0.02409639  0.02402402  0.0239521   0.0238806   0.02380952  0.02373887  0.02366864  0.02359882  0.02352941] 

AP for chair = 0.0734

 cow
im_name = 000273_gblur_r3
max IoU = 0.0390818800491

 cow
im_name = 004375_gblur_r3
max IoU = 0.0869971258208

recall =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
precision =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 

AP for cow = 0.0000

 diningtable
im_name = 002724_gblur_r3
max IoU = 0.489387747844

 diningtable
im_name = 000377_gblur_r3
max IoU = 0.423619569296

 diningtable
im_name = 007207_gblur_r3
max IoU = 0.309226071326

 diningtable
im_name = 000762_gblur_r3
max IoU = 0.335495175434

 diningtable
im_name = 004712_gblur_r3
max IoU = 0.104343779937

recall =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
precision =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 

AP for diningtable = 0.0000

 dog
im_name = 009176_gblur_r3
max IoU = 0.668164476325

 dog
im_name = 006182_gblur_r3
max IoU = 0.769658892282

 dog
im_name = 005684_gblur_r3
max IoU = 0.166999746186

 dog
im_name = 005117_gblur_r3
max IoU = 0.505422820183

recall =  [ 0.   0.   0.   0.   0.   0.   0.2  0.2  0.2  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.4  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6  0.6]
precision =  [ 0.          0.          0.          0.          0.          0.          0.14285714  0.125       0.11111111  0.2         0.18181818  0.16666667  0.15384615  0.14285714  0.13333333  0.125       0.11764706  0.11111111  0.10526316  0.1         0.0952381   0.09090909  0.08695652  0.08333333  0.08        0.07692308  0.07407407  0.07142857  0.06896552  0.06666667  0.06451613  0.0625      0.06060606  0.05882353  0.05714286  0.05555556  0.05405405  0.05263158  0.05128205  0.05        0.04878049  0.04761905  0.04651163  0.04545455  0.04444444  0.04347826  0.04255319  0.04166667  0.04081633  0.04        0.03921569  0.03846154  0.03773585  0.05555556  0.05454545  0.05357143  0.05263158  0.05172414  0.05084746  0.05        0.04918033  0.0483871   0.04761905  0.046875    0.04615385  0.04545455  0.04477612  0.04411765  0.04347826  0.04285714  0.04225352  0.04166667  0.04109589  0.04054054  0.04        0.03947368  0.03896104  0.03846154  0.03797468  0.0375      0.03703704  0.03658537  0.03614458  0.03571429  0.03529412  0.03488372  0.03448276  0.03409091  0.03370787  0.03333333  0.03296703  0.0326087   0.03225806  0.03191489  0.03157895  0.03125     0.03092784  0.03061224  0.03030303  0.03        0.02970297  0.02941176  0.02912621  0.02884615  0.02857143  0.02830189  0.02803738  0.02777778  0.02752294  0.02727273  0.02702703  0.02678571  0.02654867  0.02631579  0.02608696  0.02586207  0.02564103  0.02542373  0.02521008  0.025       0.02479339  0.02459016  0.02439024  0.02419355  0.024       0.02380952  0.02362205  0.0234375   0.02325581  0.02307692  0.02290076  0.02272727  0.02255639  0.02238806  0.02222222  0.02205882  0.02189781  0.02173913  0.02158273  0.02142857  0.0212766   0.02112676  0.02097902  0.02083333  0.02068966  0.02054795  0.02040816  0.02027027  0.02013423  0.02        0.01986755  0.01973684  0.01960784  0.01948052  0.01935484  0.01923077  0.01910828  0.01898734  0.01886792  0.01875     0.01863354  0.01851852  0.01840491  0.01829268  0.01818182  0.01807229  0.01796407  0.01785714  0.01775148  0.01764706  0.01754386  0.01744186  0.01734104  0.01724138  0.01714286  0.01704545  0.01694915  0.01685393  0.01675978  0.01666667  0.01657459  0.01648352  0.01639344  0.01630435  0.01621622  0.01612903  0.01604278  0.01595745  0.01587302  0.01578947  0.01570681  0.015625    0.01554404  0.01546392  0.01538462  0.01530612  0.01522843  0.01515152  0.01507538  0.015       0.01492537  0.01485149  0.01477833  0.01470588  0.01463415  0.01456311  0.01449275  0.01442308  0.01435407  0.01428571  0.01421801  0.01415094  0.01408451  0.01401869  0.01395349  0.01388889  0.01382488  0.01376147  0.01369863  0.01363636  0.01357466  0.01351351  0.01345291  0.01339286  0.01333333  0.01327434  0.01321586  0.01315789  0.01310044  0.01304348  0.01298701  0.01293103  0.01287554  0.01282051  0.01276596  0.01271186  0.01265823  0.01260504  0.0125523   0.0125      0.01244813  0.01239669  0.01234568  0.01229508  0.0122449   0.01219512  0.01214575  0.01209677  0.01204819  0.012       0.01195219  0.01190476  0.01185771  0.01181102  0.01176471  0.01171875  0.01167315  0.01162791  0.01158301  0.01153846  0.01149425  0.01145038  0.01140684  0.01136364  0.01132075  0.0112782   0.01123596  0.01119403  0.01115242  0.01111111  0.01107011  0.01102941  0.01098901  0.01094891  0.01090909  0.01086957  0.01083032  0.01079137  0.01075269  0.01071429  0.01067616  0.0106383   0.01060071  0.01056338  0.01052632  0.01048951  0.01045296  0.01041667  0.01038062  0.01034483  0.01030928  0.01027397  0.01023891  0.01020408  0.01016949  0.01013514  0.01010101  0.01006711  0.01003344  0.01        0.00996678  0.00993377  0.00990099  0.00986842  0.00983607  0.00980392  0.00977199  0.00974026  0.00970874  0.00967742  0.0096463   0.00961538  0.00958466  0.00955414  0.00952381  0.00949367  0.00946372  0.00943396  0.00940439  0.009375    0.00934579  0.00931677  0.00928793  0.00925926  0.00923077  0.00920245  0.00917431  0.00914634  0.00911854  0.00909091  0.00906344  0.00903614  0.00900901  0.00898204  0.00895522  0.00892857  0.00890208  0.00887574  0.00884956  0.00882353  0.00879765  0.00877193  0.00874636  0.00872093  0.00869565  0.00867052  0.00864553  0.00862069  0.00859599  0.00857143  0.00854701  0.00852273  0.00849858  0.00847458  0.0084507   0.00842697  0.00840336  0.00837989] 

AP for dog = 0.0960

 horse
im_name = 008812_gblur_r3
max IoU = 0.473013683074

 horse
im_name = 009661_gblur_r3
max IoU = 0.555515172839

 horse
im_name = 007055_gblur_r3
max IoU = 0.827287645204

 horse
im_name = 003764_gblur_r3
max IoU = 0.423992124061

recall =  [ 0.    0.    0.    0.    0.    0.25  0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 ]
precision =  [ 0.          0.          0.          0.          0.          0.16666667  0.28571429  0.25        0.22222222  0.2         0.18181818  0.16666667  0.15384615  0.14285714  0.13333333  0.125       0.11764706  0.11111111  0.10526316  0.1         0.0952381   0.09090909  0.08695652  0.08333333  0.08        0.07692308  0.07407407  0.07142857  0.06896552  0.06666667  0.06451613  0.0625      0.06060606  0.05882353  0.05714286  0.05555556  0.05405405  0.05263158  0.05128205  0.05        0.04878049  0.04761905  0.04651163  0.04545455  0.04444444  0.04347826  0.04255319  0.04166667  0.04081633  0.04        0.03921569  0.03846154  0.03773585  0.03703704  0.03636364  0.03571429  0.03508772  0.03448276  0.03389831  0.03333333  0.03278689  0.03225806  0.03174603  0.03125     0.03076923  0.03030303  0.02985075  0.02941176  0.02898551  0.02857143  0.02816901  0.02777778  0.02739726  0.02702703  0.02666667  0.02631579  0.02597403  0.02564103  0.02531646  0.025       0.02469136  0.02439024  0.02409639  0.02380952  0.02352941  0.02325581  0.02298851  0.02272727  0.02247191  0.02222222  0.02197802  0.02173913  0.02150538  0.0212766   0.02105263  0.02083333  0.02061856  0.02040816  0.02020202  0.02        0.01980198  0.01960784  0.01941748  0.01923077  0.01904762  0.01886792  0.01869159  0.01851852  0.01834862  0.01818182  0.01801802  0.01785714  0.01769912  0.01754386  0.0173913   0.01724138  0.01709402  0.01694915  0.01680672  0.01666667  0.01652893  0.01639344  0.01626016  0.01612903  0.016       0.01587302  0.01574803  0.015625    0.01550388  0.01538462  0.01526718  0.01515152  0.01503759  0.01492537  0.01481481  0.01470588  0.01459854  0.01449275  0.01438849  0.01428571  0.0141844   0.01408451  0.01398601  0.01388889  0.0137931   0.01369863  0.01360544  0.01351351  0.01342282  0.01333333  0.01324503  0.01315789  0.0130719   0.01298701  0.01290323  0.01282051  0.01273885  0.01265823  0.01257862] 

AP for horse = 0.1558

 motorbike
im_name = 009139_gblur_r3
max IoU = 0.668034534694

 motorbike
im_name = 004243_gblur_r3
max IoU = 0.663617048072

 motorbike
im_name = 006531_gblur_r3
max IoU = 0.281771466629

 motorbike
im_name = 009639_gblur_r3
max IoU = 0.69349771163

recall =  [ 0.09090909  0.18181818  0.18181818  0.27272727  0.27272727  0.36363636  0.36363636  0.36363636  0.36363636  0.36363636  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.45454545  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455  0.54545455]
precision =  [ 1.          1.          0.66666667  0.75        0.6         0.66666667  0.57142857  0.5         0.44444444  0.4         0.45454545  0.41666667  0.38461538  0.35714286  0.33333333  0.3125      0.29411765  0.27777778  0.26315789  0.25        0.23809524  0.22727273  0.2173913   0.20833333  0.2         0.19230769  0.18518519  0.17857143  0.17241379  0.16666667  0.16129032  0.15625     0.15151515  0.14705882  0.14285714  0.13888889  0.13513514  0.13157895  0.12820513  0.125       0.12195122  0.11904762  0.11627907  0.11363636  0.11111111  0.10869565  0.10638298  0.10416667  0.10204082  0.1         0.09803922  0.09615385  0.09433962  0.09259259  0.09090909  0.08928571  0.0877193   0.0862069   0.08474576  0.08333333  0.08196721  0.08064516  0.07936508  0.078125    0.07692308  0.07575758  0.07462687  0.07352941  0.07246377  0.07142857  0.07042254  0.08333333  0.08219178  0.08108108  0.08        0.07894737  0.07792208  0.07692308  0.07594937  0.075       0.07407407  0.07317073  0.07228916  0.07142857  0.07058824  0.06976744  0.06896552  0.06818182  0.06741573  0.06666667  0.06593407  0.06521739  0.06451613  0.06382979  0.06315789  0.0625      0.06185567  0.06122449  0.06060606  0.06        0.05940594  0.05882353  0.05825243  0.05769231  0.05714286  0.05660377  0.05607477  0.05555556  0.05504587  0.05454545  0.05405405  0.05357143  0.05309735  0.05263158  0.05217391  0.05172414  0.05128205  0.05084746  0.05042017  0.05        0.04958678  0.04918033  0.04878049  0.0483871   0.048       0.04761905  0.04724409  0.046875    0.04651163  0.04615385  0.04580153  0.04545455  0.04511278  0.04477612  0.04444444  0.04411765  0.04379562  0.04347826  0.04316547  0.04285714  0.04255319  0.04225352  0.04195804  0.04166667  0.04137931  0.04109589  0.04081633  0.04054054  0.04026846  0.04        0.0397351   0.03947368  0.03921569  0.03896104  0.03870968  0.03846154  0.03821656  0.03797468  0.03773585  0.0375      0.03726708  0.03703704  0.03680982  0.03658537  0.03636364  0.03614458  0.03592814  0.03571429  0.03550296  0.03529412  0.03508772  0.03488372  0.03468208  0.03448276  0.03428571  0.03409091  0.03389831  0.03370787  0.03351955  0.03333333  0.03314917  0.03296703  0.03278689  0.0326087   0.03243243  0.03225806  0.03208556  0.03191489  0.03174603  0.03157895  0.03141361  0.03125     0.03108808  0.03092784  0.03076923  0.03061224  0.03045685  0.03030303  0.03015075  0.03        0.02985075  0.02970297  0.02955665  0.02941176  0.02926829  0.02912621  0.02898551  0.02884615  0.02870813  0.02857143  0.02843602  0.02830189  0.02816901  0.02803738  0.02790698  0.02777778  0.02764977  0.02752294  0.02739726  0.02727273  0.02714932  0.02702703  0.02690583  0.02678571  0.02666667  0.02654867  0.02643172  0.02631579  0.02620087  0.02608696  0.02597403  0.02586207  0.02575107  0.02564103  0.02553191  0.02542373] 

AP for motorbike = 0.3595

 person
im_name = 004709_gblur_r3
max IoU = 0.551151700876

 person
im_name = 004072_gblur_r3
max IoU = 0.842935789127

 person
im_name = 000502_gblur_r3
max IoU = 0.786989440089

 person
im_name = 005117_gblur_r3
max IoU = 0.68342879948

 person
im_name = 003012_gblur_r3
max IoU = 0.82021578518

 person
im_name = 007161_gblur_r3
max IoU = 0.720834972622

 person
im_name = 000377_gblur_r3
max IoU = 0.703829232524

 person
im_name = 002365_gblur_r3
max IoU = 0.827026392617

 person
im_name = 000762_gblur_r3
max IoU = 0.600797058883

 person
im_name = 001482_gblur_r3
max IoU = 0.43452658485

 person
im_name = 006087_gblur_r3
max IoU = 0.762404505619

 person
im_name = 007360_gblur_r3
max IoU = 0.499562744699

 person
im_name = 009139_gblur_r3
max IoU = 0.773414124105

 person
im_name = 004712_gblur_r3
max IoU = 0.608534617809

 person
im_name = 009661_gblur_r3
max IoU = 0.644322791849

 person
im_name = 000458_gblur_r3
max IoU = 0.682462284483

 person
im_name = 004639_gblur_r3
max IoU = 0.794277557404

 person
im_name = 008110_gblur_r3
max IoU = 0.538466066122

 person
im_name = 007207_gblur_r3
max IoU = 0.614196911828

 person
im_name = 006775_gblur_r3
max IoU = 0.493816368232

 person
im_name = 002325_gblur_r3
max IoU = 0.555140859076

 person
im_name = 005218_gblur_r3
max IoU = 0.456855044956

 person
im_name = 006481_gblur_r3
max IoU = 0.226824877543

 person
im_name = 003764_gblur_r3
max IoU = 0.48735916577

 person
im_name = 007476_gblur_r3
max IoU = 0.646121897224

 person
im_name = 005105_gblur_r3
max IoU = 0.253864965795

 person
im_name = 007785_gblur_r3
max IoU = 0.577372828417

 person
im_name = 003701_gblur_r3
max IoU = 0.789673721808

 person
im_name = 008812_gblur_r3
max IoU = 0.690851165353

 person
im_name = 004243_gblur_r3
max IoU = 0.365357003002

 person
im_name = 006531_gblur_r3
max IoU = 0.132166151734

 person
im_name = 000538_gblur_r3
max IoU = 0.140247916503

 person
im_name = 000883_gblur_r3
max IoU = 0.411648296017

 person
im_name = 006307_gblur_r3
max IoU = 0.114770641086

recall =  [ 0.01333333  0.02666667  0.04        0.05333333  0.05333333  0.06666667  0.06666667  0.08        0.09333333  0.09333333  0.09333333  0.10666667  0.10666667  0.10666667  0.12        0.12        0.12        0.12        0.12        0.13333333  0.13333333  0.13333333  0.13333333  0.14666667  0.14666667  0.14666667  0.16        0.17333333  0.18666667  0.18666667  0.18666667  0.2         0.21333333  0.22666667  0.22666667  0.22666667  0.22666667  0.24        0.24        0.24        0.24        0.24        0.24        0.24        0.24        0.24        0.24        0.24        0.24        0.24        0.24        0.24        0.24        0.24        0.24        0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.25333333  0.26666667  0.26666667  0.26666667  0.26666667  0.28        0.28        0.28        0.28        0.28        0.28        0.28        0.28        0.28        0.28        0.28        0.28        0.28        0.29333333  0.29333333  0.29333333  0.29333333  0.29333333  0.29333333  0.29333333  0.29333333  0.29333333  0.29333333  0.29333333  0.29333333  0.29333333  0.29333333  0.29333333  0.29333333  0.30666667  0.30666667  0.30666667  0.30666667  0.30666667  0.30666667  0.30666667  0.30666667  0.30666667  0.30666667  0.30666667  0.30666667  0.30666667  0.30666667  0.30666667  0.30666667  0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.32        0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.34666667  0.34666667  0.34666667  0.34666667  0.34666667  0.34666667  0.34666667  0.34666667  0.34666667  0.34666667  0.34666667  0.34666667  0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36        0.36      ]
precision =  [ 1.          1.          1.          1.          0.8         0.83333333  0.71428571  0.75        0.77777778  0.7         0.63636364  0.66666667  0.61538462  0.57142857  0.6         0.5625      0.52941176  0.5         0.47368421  0.5         0.47619048  0.45454545  0.43478261  0.45833333  0.44        0.42307692  0.44444444  0.46428571  0.48275862  0.46666667  0.4516129   0.46875     0.48484848  0.5         0.48571429  0.47222222  0.45945946  0.47368421  0.46153846  0.45        0.43902439  0.42857143  0.41860465  0.40909091  0.4         0.39130435  0.38297872  0.375       0.36734694  0.36        0.35294118  0.34615385  0.33962264  0.33333333  0.32727273  0.33928571  0.33333333  0.32758621  0.3220339   0.31666667  0.31147541  0.30645161  0.3015873   0.296875    0.29230769  0.28787879  0.28358209  0.27941176  0.27536232  0.27142857  0.26760563  0.26388889  0.26027397  0.25675676  0.25333333  0.25        0.24675325  0.24358974  0.24050633  0.2375      0.2345679   0.23170732  0.22891566  0.22619048  0.22352941  0.22093023  0.2183908   0.21590909  0.21348315  0.21111111  0.20879121  0.20652174  0.20430108  0.20212766  0.2         0.19791667  0.19587629  0.19387755  0.19191919  0.19        0.18811881  0.18627451  0.18446602  0.18269231  0.18095238  0.17924528  0.17757009  0.17592593  0.17431193  0.17272727  0.17117117  0.16964286  0.16814159  0.16666667  0.16521739  0.1637931   0.16239316  0.16101695  0.15966387  0.15833333  0.15702479  0.1557377   0.15447154  0.15322581  0.152       0.15079365  0.15748031  0.15625     0.15503876  0.15384615  0.16030534  0.15909091  0.15789474  0.15671642  0.15555556  0.15441176  0.15328467  0.15217391  0.15107914  0.15        0.14893617  0.14788732  0.14685315  0.15277778  0.15172414  0.15068493  0.14965986  0.14864865  0.14765101  0.14666667  0.14569536  0.14473684  0.14379085  0.14285714  0.14193548  0.14102564  0.14012739  0.13924051  0.13836478  0.14375     0.14285714  0.14197531  0.14110429  0.1402439   0.13939394  0.13855422  0.13772455  0.13690476  0.13609467  0.13529412  0.13450292  0.13372093  0.13294798  0.13218391  0.13142857  0.13636364  0.13559322  0.13483146  0.13407821  0.13333333  0.13259669  0.13186813  0.13114754  0.13043478  0.12972973  0.12903226  0.12834225  0.12765957  0.12698413  0.12631579  0.12565445  0.125       0.12435233  0.12371134  0.12307692  0.12244898  0.12182741  0.12121212  0.12060302  0.12        0.11940299  0.11881188  0.1182266   0.11764706  0.11707317  0.11650485  0.11594203  0.11538462  0.11483254  0.11428571  0.11374408  0.11320755  0.11267606  0.11214953  0.11162791  0.11111111  0.11059908  0.11009174  0.10958904  0.10909091  0.10859729  0.10810811  0.10762332  0.10714286  0.10666667  0.10619469  0.10572687  0.10526316  0.10480349  0.10434783  0.1038961   0.10344828  0.10300429  0.1025641   0.10212766  0.10169492  0.10126582  0.10084034  0.10041841  0.1         0.09958506  0.09917355  0.09876543  0.09836066  0.09795918  0.09756098  0.09716599  0.09677419  0.09638554  0.096       0.09561753  0.0952381   0.09486166  0.09448819  0.09411765  0.09375     0.09338521  0.09302326  0.09266409  0.09230769  0.09195402  0.09160305  0.09125475  0.09090909  0.09056604  0.09022556  0.09022556  0.08988764  0.08955224  0.08921933  0.08888889  0.08856089  0.08823529  0.08791209  0.08759124  0.08727273  0.08695652  0.0866426   0.08633094  0.08602151  0.08571429  0.08540925  0.08510638  0.08480565  0.08450704  0.08421053  0.08391608  0.08362369  0.08333333  0.08304498  0.08275862  0.08247423  0.08219178  0.08191126  0.08163265  0.08135593  0.08108108  0.08080808  0.08053691  0.08026756  0.08        0.07973422  0.0794702   0.07920792  0.07894737  0.07868852  0.07843137  0.0781759   0.07792208  0.0776699   0.07741935  0.07717042  0.07692308  0.07667732  0.07643312  0.07619048  0.07594937  0.07570978  0.0754717   0.07523511  0.075       0.07476636  0.07453416  0.07430341  0.07407407  0.07384615  0.07361963  0.0733945   0.07317073  0.07294833  0.07272727  0.07250755  0.07228916  0.07207207  0.07185629  0.07164179  0.07142857  0.07121662  0.07100592  0.07079646  0.07058824  0.07038123  0.07017544  0.06997085  0.06976744  0.06956522  0.06936416  0.06916427  0.06896552  0.06876791  0.06857143  0.06837607  0.06818182  0.06798867  0.07062147  0.07042254  0.07022472  0.07002801  0.0698324   0.06963788  0.06944444  0.06925208  0.06906077  0.06887052  0.06868132  0.06849315  0.06830601  0.06811989  0.06793478  0.06775068  0.06756757  0.06738544  0.0672043   0.06702413  0.06684492  0.06666667  0.06648936  0.066313    0.06613757  0.06596306  0.06578947  0.0656168   0.06544503  0.06527415  0.06510417  0.06493506  0.06476684  0.06459948  0.06443299  0.06426735  0.06410256  0.06393862  0.06377551  0.06361323  0.06345178  0.06329114  0.06313131  0.06297229  0.06281407  0.06265664  0.0625      0.06234414  0.06218905  0.06203474  0.06188119  0.0617284   0.06157635  0.06142506  0.06127451  0.06112469  0.06097561  0.06082725  0.06067961  0.06053269  0.06038647  0.06024096  0.0625      0.06235012  0.06220096  0.06205251  0.06190476  0.06175772  0.06161137  0.06146572  0.06132075  0.06117647  0.06103286  0.06088993  0.06308411  0.06293706  0.0627907   0.06264501  0.0625      0.06235566  0.06221198  0.06206897  0.06192661  0.0617849   0.06164384  0.06150342  0.06136364  0.06122449  0.06108597  0.06094808  0.06081081  0.06067416  0.06053812  0.06040268  0.06026786  0.06013363  0.06        0.05986696  0.05973451  0.05960265  0.05947137  0.05934066  0.05921053  0.05908096  0.05895197  0.05882353  0.05869565  0.05856833  0.05844156  0.05831533  0.05818966  0.05806452  0.05793991  0.05781585  0.05769231  0.0575693   0.05744681  0.05732484  0.05720339  0.05708245  0.05696203  0.05684211  0.05672269  0.05660377  0.05648536  0.05636743  0.05625     0.05613306  0.0560166   0.05590062  0.05578512  0.0556701   0.05555556  0.05544148  0.05532787  0.05521472  0.05510204  0.05498982  0.05487805  0.05476673  0.05465587  0.05454545  0.05443548  0.05432596  0.05421687  0.05410822  0.054       0.05389222  0.05378486  0.05367793  0.05357143  0.05346535  0.05335968  0.05325444  0.05314961  0.05304519  0.05294118  0.05283757  0.05273438  0.05263158  0.05252918  0.05242718  0.05232558  0.05222437  0.05212355  0.05202312  0.05192308  0.05182342  0.05172414  0.05162524  0.05152672  0.05142857  0.0513308   0.0512334   0.05113636  0.0510397   0.0509434   0.05084746  0.05075188  0.05065666  0.0505618   0.05046729  0.05037313  0.05027933  0.05018587  0.05009276  0.05        0.04990758  0.0498155   0.04972376  0.04963235  0.04954128  0.04954128  0.04945055  0.04936015  0.04927007] 

AP for person = 0.2100

 pottedplant
im_name = 004712_gblur_r3
max IoU = 0.801163135355

 pottedplant
im_name = 006307_gblur_r3
max IoU = 0.104116120096

recall =  [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5]
precision =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.0021097   0.00210526  0.00210084  0.00209644  0.00209205  0.00208768  0.00208333  0.002079    0.00207469  0.00207039  0.00206612  0.00206186  0.00205761  0.00205339  0.00204918  0.00204499] 

AP for pottedplant = 0.0012

 sheep
im_name = 000458_gblur_r3
max IoU = 0.527125934708

 sheep
im_name = 004646_gblur_r3
max IoU = 0.103397272011

 sheep
im_name = 004072_gblur_r3
max IoU = 0.0557673321632

recall =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333]
precision =  [ 0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.04347826  0.04166667  0.04        0.03846154  0.03703704  0.03571429  0.03448276  0.03333333  0.03225806  0.03125     0.03030303  0.02941176  0.02857143  0.02777778  0.02702703  0.02631579  0.02564103  0.025       0.02439024  0.02380952  0.02325581  0.02272727  0.02222222  0.02173913  0.0212766   0.02083333  0.02040816  0.02        0.01960784  0.01923077  0.01886792  0.01851852  0.01818182  0.01785714  0.01754386  0.01724138  0.01694915  0.01666667  0.01639344  0.01612903  0.01587302  0.015625    0.01538462  0.01515152  0.01492537  0.01470588  0.01449275  0.01428571  0.01408451  0.01388889  0.01369863  0.01351351  0.01333333  0.01315789  0.01298701  0.01282051  0.01265823  0.0125      0.01234568  0.01219512  0.01204819  0.01190476  0.01176471  0.01162791  0.01149425  0.01136364  0.01123596  0.01111111  0.01098901  0.01086957  0.01075269  0.0106383   0.01052632  0.01041667  0.01030928  0.01020408  0.01010101  0.01        0.00990099  0.00980392  0.00970874  0.00961538  0.00952381  0.00943396  0.00934579  0.00925926  0.00917431  0.00909091  0.00900901  0.00892857  0.00884956  0.00877193  0.00869565  0.00862069  0.00854701  0.00847458  0.00840336  0.00833333  0.00826446  0.00819672  0.00813008  0.00806452  0.008       0.00793651  0.00787402  0.0078125   0.00775194  0.00769231  0.00763359  0.00757576  0.0075188   0.00746269  0.00740741  0.00735294  0.00729927  0.00724638  0.00719424  0.00714286  0.0070922   0.00704225  0.00699301  0.00694444  0.00689655  0.00684932  0.00680272  0.00675676  0.00671141  0.00666667  0.00662252  0.00657895  0.00653595  0.00649351  0.00645161  0.00641026  0.00636943  0.00632911  0.00628931  0.00625     0.00621118  0.00617284  0.00613497  0.00609756  0.00606061  0.0060241   0.00598802  0.00595238  0.00591716  0.00588235  0.00584795  0.00581395  0.00578035  0.00574713  0.00571429  0.00568182  0.00564972  0.00561798  0.00558659  0.00555556  0.00552486  0.00549451  0.00546448  0.00543478  0.00540541  0.00537634  0.00534759  0.00531915  0.00529101  0.00526316  0.0052356   0.00520833  0.00518135  0.00515464  0.00512821  0.00510204  0.00507614  0.00505051  0.00502513  0.005       0.00497512  0.0049505   0.00492611  0.00490196  0.00487805  0.00485437  0.00483092  0.00480769  0.00478469  0.0047619   0.00473934  0.00471698  0.00469484  0.0046729   0.00465116  0.00462963  0.00460829  0.00458716  0.00456621  0.00454545  0.00452489  0.0045045   0.0044843   0.00446429  0.00444444  0.00442478  0.00440529  0.00438596  0.00436681  0.00434783  0.004329    0.00431034  0.00429185  0.0042735   0.00425532  0.00423729  0.00421941  0.00420168  0.0041841   0.00416667  0.00414938  0.00413223  0.00411523  0.00409836  0.00408163  0.00406504  0.00404858  0.00403226  0.00401606  0.004       0.00398406  0.00396825  0.00395257  0.00393701  0.00392157  0.00390625  0.00389105  0.00387597  0.003861    0.00384615  0.00383142  0.00381679  0.00380228  0.00378788  0.00377358  0.0037594   0.00374532  0.00373134  0.00371747  0.0037037   0.00369004  0.00367647  0.003663    0.00364964  0.00363636  0.00362319  0.00361011  0.00359712  0.00358423  0.00357143  0.00355872  0.0035461   0.00353357  0.00352113  0.00350877  0.0034965   0.00348432] 

AP for sheep = 0.0158

 sofa
im_name = 008395_gblur_r3
max IoU = 0.710749639423

 sofa
im_name = 004096_gblur_r3
max IoU = 0.667773533193

 sofa
im_name = 007785_gblur_r3
max IoU = 0.355580633924

 sofa
im_name = 006307_gblur_r3
max IoU = 0.359630963214

 sofa
im_name = 000658_gblur_r3
max IoU = 0.347839994523

 sofa
im_name = 008543_gblur_r3
max IoU = 0.371986881928

recall =  [ 0.          0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333]
precision =  [ 0.          0.5         0.33333333  0.25        0.2         0.16666667  0.14285714  0.125       0.11111111  0.1         0.09090909  0.08333333  0.07692308  0.07142857  0.06666667  0.0625      0.05882353  0.05555556  0.05263158  0.05        0.04761905  0.04545455  0.04347826  0.04166667  0.04        0.03846154  0.03703704  0.03571429  0.03448276  0.03333333  0.03225806  0.03125     0.03030303  0.02941176  0.02857143  0.02777778  0.02702703  0.02631579  0.02564103  0.025       0.02439024  0.02380952  0.02325581  0.02272727  0.02222222  0.02173913  0.0212766   0.02083333  0.02040816  0.02        0.01960784  0.01923077  0.01886792  0.01851852  0.01818182  0.01785714  0.01754386  0.01724138  0.01694915  0.01666667  0.01639344  0.01612903  0.01587302  0.015625    0.01538462  0.01515152  0.01492537  0.01470588  0.01449275  0.01428571  0.01408451  0.01388889  0.01369863  0.01351351  0.01333333  0.01315789  0.01298701  0.01282051  0.01265823  0.0125      0.01234568  0.01219512  0.01204819  0.01190476  0.01176471  0.01162791  0.01149425  0.01136364  0.01123596  0.01111111  0.01098901  0.01086957  0.01075269  0.0106383   0.01052632  0.01041667  0.01030928  0.01020408  0.01010101  0.01        0.00990099  0.00980392  0.00970874  0.00961538  0.00952381  0.00943396  0.00934579  0.00925926  0.00917431  0.00909091  0.00900901  0.00892857  0.00884956  0.00877193  0.00869565  0.00862069  0.00854701  0.00847458  0.00840336  0.00833333  0.00826446  0.00819672  0.00813008  0.00806452  0.008       0.00793651  0.00787402  0.0078125   0.00775194  0.00769231  0.00763359  0.00757576  0.01503759  0.01492537  0.01481481  0.01470588  0.01459854  0.01449275  0.01438849  0.01428571  0.0141844   0.01408451  0.01398601  0.01388889  0.0137931   0.01369863  0.01360544  0.01351351  0.01342282  0.01333333  0.01324503  0.01315789  0.0130719   0.01298701  0.01290323  0.01282051  0.01273885  0.01265823  0.01257862  0.0125      0.01242236  0.01234568  0.01226994  0.01219512  0.01212121  0.01204819  0.01197605  0.01190476  0.01183432  0.01176471  0.01169591  0.01162791  0.01156069  0.01149425  0.01142857  0.01136364  0.01129944  0.01123596  0.01117318  0.01111111  0.01104972  0.01098901  0.01092896  0.01086957  0.01081081  0.01075269  0.01069519  0.0106383   0.01058201  0.01052632  0.0104712   0.01041667  0.01036269  0.01030928  0.01025641  0.01020408  0.01015228  0.01010101  0.01005025  0.01        0.00995025  0.00990099  0.00985222  0.00980392  0.0097561   0.00970874  0.00966184  0.00961538  0.00956938  0.00952381  0.00947867  0.00943396  0.00938967  0.00934579  0.00930233  0.00925926  0.00921659  0.00917431  0.00913242  0.00909091  0.00904977  0.00900901  0.00896861  0.00892857  0.00888889] 

AP for sofa = 0.0936

 train
im_name = 005172_gblur_r3
max IoU = 0.789644934731

 train
im_name = 008065_gblur_r3
max IoU = 0.261038611592

 train
im_name = 005011_gblur_r3
max IoU = 0.225470097106

recall =  [ 0.          0.          0.          0.          0.          0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333]
precision =  [ 0.          0.          0.          0.          0.          0.16666667  0.14285714  0.125       0.11111111  0.1         0.09090909  0.08333333  0.07692308  0.07142857  0.06666667  0.0625      0.05882353  0.05555556  0.05263158  0.05        0.04761905  0.04545455  0.04347826  0.04166667  0.04        0.03846154  0.03703704  0.03571429  0.03448276  0.03333333  0.03225806  0.03125     0.03030303  0.02941176  0.02857143  0.02777778  0.02702703  0.02631579  0.02564103  0.025       0.02439024  0.02380952  0.02325581  0.02272727  0.02222222  0.02173913  0.0212766   0.02083333  0.02040816  0.02        0.01960784  0.01923077  0.01886792  0.01851852  0.01818182  0.01785714  0.01754386  0.01724138  0.01694915  0.01666667  0.01639344  0.01612903  0.01587302  0.015625    0.01538462  0.01515152  0.01492537  0.01470588  0.01449275  0.01428571  0.01408451  0.01388889  0.01369863  0.01351351  0.01333333  0.01315789  0.01298701  0.01282051  0.01265823  0.0125      0.01234568  0.01219512  0.01204819  0.01190476  0.01176471  0.01162791  0.01149425  0.01136364  0.01123596  0.01111111  0.01098901  0.01086957  0.01075269  0.0106383   0.01052632  0.01041667  0.01030928  0.01020408  0.01010101  0.01        0.00990099  0.00980392  0.00970874  0.00961538  0.00952381  0.00943396  0.00934579  0.00925926  0.00917431  0.00909091  0.00900901  0.00892857  0.00884956  0.00877193  0.00869565  0.00862069  0.00854701  0.00847458  0.00840336  0.00833333  0.00826446  0.00819672  0.00813008  0.00806452  0.008       0.00793651  0.00787402  0.0078125   0.00775194  0.00769231  0.00763359  0.00757576  0.0075188   0.00746269  0.00740741  0.00735294  0.00729927  0.00724638  0.00719424  0.00714286  0.0070922   0.00704225  0.00699301  0.00694444  0.00689655  0.00684932  0.00680272  0.00675676  0.00671141  0.00666667  0.00662252  0.00657895  0.00653595  0.00649351  0.00645161  0.00641026  0.00636943  0.00632911  0.00628931  0.00625     0.00621118  0.00617284  0.00613497  0.00609756  0.00606061  0.0060241 ] 

AP for train = 0.0606

 tvmonitor
im_name = 001704_gblur_r3
max IoU = 0.751205943194

 tvmonitor
im_name = 006688_gblur_r3
max IoU = 0.538384215798

 tvmonitor
im_name = 006307_gblur_r3
max IoU = 0.103146118279

recall =  [ 0.    0.    0.    0.    0.25  0.25  0.25  0.25  0.25  0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 ]
precision =  [ 0.          0.          0.          0.          0.2         0.16666667  0.14285714  0.125       0.11111111  0.2         0.18181818  0.16666667  0.15384615  0.14285714  0.13333333  0.125       0.11764706  0.11111111  0.10526316  0.1         0.0952381   0.09090909  0.08695652  0.08333333  0.08        0.07692308  0.07407407  0.07142857  0.06896552  0.06666667  0.06451613  0.0625      0.06060606  0.05882353  0.05714286  0.05555556  0.05405405  0.05263158  0.05128205  0.05        0.04878049  0.04761905  0.04651163  0.04545455  0.04444444  0.04347826  0.04255319  0.04166667  0.04081633  0.04        0.03921569  0.03846154  0.03773585  0.03703704  0.03636364  0.03571429  0.03508772  0.03448276  0.03389831  0.03333333  0.03278689  0.03225806  0.03174603  0.03125     0.03076923  0.03030303  0.02985075  0.02941176  0.02898551  0.02857143  0.02816901  0.02777778  0.02739726  0.02702703  0.02666667  0.02631579  0.02597403  0.02564103  0.02531646  0.025       0.02469136  0.02439024  0.02409639  0.02380952  0.02352941  0.02325581  0.02298851  0.02272727  0.02247191  0.02222222  0.02197802  0.02173913  0.02150538  0.0212766   0.02105263  0.02083333  0.02061856  0.02040816  0.02020202  0.02        0.01980198  0.01960784  0.01941748  0.01923077  0.01904762  0.01886792  0.01869159  0.01851852  0.01834862  0.01818182  0.01801802  0.01785714  0.01769912  0.01754386  0.0173913   0.01724138  0.01709402  0.01694915  0.01680672  0.01666667  0.01652893  0.01639344  0.01626016  0.01612903  0.016       0.01587302  0.01574803  0.015625    0.01550388  0.01538462  0.01526718  0.01515152  0.01503759  0.01492537  0.01481481  0.01470588  0.01459854  0.01449275  0.01438849  0.01428571  0.0141844   0.01408451  0.01398601  0.01388889  0.0137931   0.01369863  0.01360544  0.01351351  0.01342282  0.01333333  0.01324503  0.01315789  0.0130719   0.01298701  0.01290323  0.01282051  0.01273885  0.01265823  0.01257862  0.0125      0.01242236  0.01234568  0.01226994  0.01219512  0.01212121  0.01204819  0.01197605  0.01190476  0.01183432  0.01176471  0.01169591  0.01162791  0.01156069  0.01149425  0.01142857  0.01136364  0.01129944  0.01123596  0.01117318  0.01111111  0.01104972  0.01098901  0.01092896  0.01086957  0.01081081  0.01075269  0.01069519  0.0106383   0.01058201  0.01052632  0.0104712   0.01041667  0.01036269  0.01030928  0.01025641  0.01020408  0.01015228  0.01010101  0.01005025  0.01        0.00995025  0.00990099  0.00985222  0.00980392  0.0097561   0.00970874  0.00966184  0.00961538  0.00956938  0.00952381  0.00947867  0.00943396  0.00938967  0.00934579  0.00930233  0.00925926  0.00921659  0.00917431  0.00913242  0.00909091  0.00904977  0.00900901  0.00896861  0.00892857  0.00888889  0.00884956  0.00881057  0.00877193  0.00873362  0.00869565  0.00865801  0.00862069  0.00858369  0.00854701  0.00851064  0.00847458  0.00843882  0.00840336  0.0083682   0.00833333  0.00829876  0.00826446  0.00823045  0.00819672  0.00816327  0.00813008  0.00809717  0.00806452  0.00803213  0.008       0.00796813  0.00793651  0.00790514  0.00787402  0.00784314  0.0078125   0.0077821   0.00775194  0.00772201  0.00769231  0.00766284  0.00763359  0.00760456  0.00757576  0.00754717  0.0075188   0.00749064  0.00746269  0.00743494  0.00740741  0.00738007  0.00735294  0.00732601  0.00729927  0.00727273  0.00724638  0.00722022  0.00719424  0.00716846  0.00714286  0.00711744  0.0070922   0.00706714  0.00704225  0.00701754  0.00699301  0.00696864  0.00694444  0.00692042  0.00689655  0.00687285  0.00684932  0.00682594  0.00680272  0.00677966  0.00675676  0.00673401  0.00671141  0.00668896  0.00666667  0.00664452  0.00662252  0.00660066  0.00657895  0.00655738  0.00653595  0.00651466  0.00649351  0.00647249  0.00645161  0.00643087  0.00641026  0.00638978  0.00636943  0.00634921  0.00632911  0.00630915  0.00628931  0.00626959  0.00625     0.00623053  0.00621118  0.00619195  0.00617284  0.00615385  0.00613497  0.00611621  0.00609756  0.00607903  0.00606061  0.0060423   0.0060241   0.00600601  0.00598802  0.00597015  0.00595238  0.00593472  0.00591716  0.00589971  0.00588235  0.0058651   0.00584795  0.0058309   0.00581395  0.0057971   0.00578035  0.00576369  0.00574713  0.00573066  0.00571429  0.00569801  0.00568182  0.00566572  0.00564972  0.0056338   0.00561798  0.00560224  0.00558659  0.00557103  0.00555556  0.00554017  0.00552486  0.00550964  0.00549451  0.00547945  0.00546448  0.00544959  0.00543478  0.00542005  0.00540541  0.00539084  0.00537634  0.00536193  0.00534759  0.00533333  0.00531915  0.00530504  0.00529101  0.00527704  0.00526316  0.00524934  0.0052356   0.00522193  0.00520833  0.00519481  0.00518135  0.00516796  0.00515464  0.00514139  0.00512821  0.00511509  0.00510204  0.00508906  0.00507614  0.00506329  0.00505051  0.00503778  0.00502513  0.00501253  0.005       0.00498753  0.00497512  0.00496278  0.0049505   0.00493827  0.00492611  0.004914    0.00490196  0.00488998  0.00487805  0.00486618  0.00485437  0.00484262  0.00483092  0.00481928  0.00480769  0.00479616  0.00478469  0.00477327  0.0047619   0.00475059  0.00473934  0.00472813  0.00471698  0.00470588  0.00469484  0.00468384  0.0046729   0.004662    0.00465116  0.00464037  0.00462963  0.00461894  0.00460829  0.0045977   0.00458716  0.00457666  0.00456621  0.00455581  0.00454545  0.00453515  0.00452489  0.00451467  0.0045045   0.00449438  0.0044843   0.00447427  0.00446429  0.00445434  0.00444444  0.00443459  0.00442478  0.00441501  0.00440529  0.0043956   0.00438596  0.00437637  0.00436681  0.0043573   0.00434783  0.00433839  0.004329    0.00431965  0.00431034  0.00430108  0.00429185  0.00428266] 

AP for tvmonitor = 0.1091

Mean AP = 0.1366
~~~~~~~~
Results:
0.000
0.260
0.018
0.000
0.000
0.583
0.387
0.309
0.073
0.000
0.000
0.096
0.156
0.360
0.210
0.001
0.016
0.094
0.061
0.109
0.137
~~~~~~~~

--------------------------------------------------------------
Results computed with the **unofficial** Python eval code.
Results should be very close to the official MATLAB eval code.
Recompute with `./tools/reval.py --matlab ...` for your paper.
-- Thanks, The Management
--------------------------------------------------------------
28.45user 7.61system 0:35.95elapsed 100%CPU (0avgtext+0avgdata 1768992maxresident)k
0inputs+1304outputs (0major+310537minor)pagefaults 0swaps
